val source = CSVFile("output.csv")

val tokenizer = {
SimpleEnglishTokenizer() ~>            // tokenize on space and punctuation
WordsAndNumbersOnlyFilter() ~>         // ignore non-words and non-numbers
CaseFolder() ~>                        // lowercase everything
MinimumLengthFilter(3)                 // take terms with >=3 characters 
}

val text = {
source ~>                              // read from the source file
Column(1) ~>                           // select column containing text
TokenizeWith(tokenizer) ~>             // tokenize with tokenizer above
TermCounter() ~>                       // collect counts (needed below)
TermMinimumDocumentCountFilter(30) ~>   // filter terms in <4 docs
TermStopListFilter(List("a", "and", "I", "but", "what")) ~> // stopword list
TermDynamicStopListFilter(10) ~>       // filter out 30 most common terms  
DocumentMinimumLengthFilter(5)         // take only docs with >=5 terms 
}

