let audioFormstDesc = descriptions[0] as CMAudioFormatDescription

import AVFoundation
import CoreMedia
import MediaPlayer

class ViewController: UIViewController
{
    override func viewDidLoad()
    {
        super.viewDidLoad()

        let query = MPMediaQuery.songsQuery()
        let song = query.items[0] as MPMediaItem
        let url = song.valueForProperty(MPMediaItemPropertyAssetURL) as NSURL
        let songAsset = AVURLAsset.URLAssetWithURL(url, options: nil)
        let trackAsset = songAsset.tracks[0] as AVAssetTrack
        if let descriptions = trackAsset.formatDescriptions
        {
            let audioFormstDesc = descriptions[0] as CMAudioFormatDescription
            let streamBasicDescription = CMAudioFormatDescriptionGetStreamBasicDescription(audioFormstDesc)
        }
    }
}

MPMediaQuery *query = [MPMediaQuery songsQuery];
MPMediaItem *song = [[query items] objectAtIndex:0];
NSURL *url = [song valueForProperty: MPMediaItemPropertyAssetURL];
AVURLAsset *songAsset = [AVURLAsset URLAssetWithURL:url options:nil];
AVAssetTrack *trackAsset = songAsset.tracks[0];

UInt32 sampleRate = 0, channelCount = 0;
NSArray* descriptions = trackAsset.formatDescriptions;
CMAudioFormatDescriptionRef audioFormstDesc = (__bridge CMAudioFormatDescriptionRef)descriptions[0];
const AudioStreamBasicDescription* audioStreamDesc = CMAudioFormatDescriptionGetStreamBasicDescription(audioFormstDesc);
if(audioStreamDesc)
{
    sampleRate = audioStreamDesc->mSampleRate;
    channelCount = audioStreamDesc->mChannelsPerFrame;
}

println(descriptions[0])
<CMAudioFormatDescription 0x15d3b690 [0x387e5ad0]>

