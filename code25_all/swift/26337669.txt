    //NSString videoPath=NSBundle.mainBundle().l
        var videoURL=NSBundle.mainBundle().URLForResource("video", withExtension: "mp4")

        var assetOptions = [AVURLAssetPreferPreciseDurationAndTimingKey : 1]
        videoAsset=AVURLAsset(URL: videoURL, options: assetOptions)
        var error:NSError?

        var videoAssetReader=AVAssetReader(asset: videoAsset, error: &error)

        //var duration = CMTimeGetSeconds(videoAsset.duration)
        //println(videoAsset.duration)
       // println(duration)

        if error != nil
        {
            println(error)
        }

        var tracksArray=videoAsset?.tracksWithMediaType(AVMediaTypeVideo)
        var audio=videoAsset?.tracksWithMediaType(AVMediaTypeAudio)

        println(tracksArray?)
        var videotrack = tracksArray?[0] as AVAssetTrack

        //println(videotrack?.size)
        fps = videotrack.nominalFrameRate
        var videoSetting = [kCVPixelBufferPixelFormatTypeKey : kCVPixelFormatType_32RGBA]

        var videoTrackOutput=AVAssetReaderTrackOutput(track:videotrack as AVAssetTrack , outputSettings:videoSetting)

       // videoTrackOutput.outputSettings=

        if videoAssetReader.canAddOutput(videoTrackOutput)
        {
            println(videoTrackOutput)
            videoAssetReader.addOutput(videoTrackOutput)
            videoAssetReader.startReading()
        }

        var image=GeneralPreview()
        var uiImage=UIImage(CGImage: image)


        if videoAssetReader.status == AVAssetReaderStatus.Reading{

            var sampleBuffer  = videoTrackOutput.copyNextSampleBuffer()
            println(sampleBuffer)

            //var imageData: NSData = AVCaptureStillImageOutput.jpegStillImageNSDataRepresentation(sampleBuffer?)
            //var image: UIImage = UIImage(data: imageData)
        }

