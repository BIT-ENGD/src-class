    chrName-chrStart-chrEnd,gm12878,h1-hesc,hela-s3,hepg2,huvec,k562
    chr21-10861860-10862010,0.6904761905,0,0,1.2555555556,0.25,1.05
    chr21-10896160-10896310,0.35,2.4934782609,0.8181818182,1.05,0.75,1.9611111111
    chr21-10936080-10936230,1.525,0.2,0.525,1.0823529412,0.7409090909,0.85
    chr21-10972180-10972330,0.7333333333,1,0.67,1.7227272727,0.9571428571,0.8823529412
    chr21-11059120-11059270,3.7268292683,2.9347826087,1.3833333333,3.328358209,4.35,2.31
    chr21-11101660-11101810,1.78,5.328125,1.05,0,2.9916666667,1.25
    chr21-11181780-11181930,2.9542857143,4.3173913043,0.9666666667,2.65,4.772972973,1.01
    chr21-14911600-14911750,0.7882352941,0,0,0,0.3,1.25
    chr21-14973280-14973430,0.3,0.65,0,0.4,0.1,0

-- see if the file exists
function file_exists(file)
  local f = io.open(file, "rb")
  if f then f:close() end
  return f ~= nil
end

-- get all lines from a file, returns an empty 
-- list/table if the file does not exist
function lines_from(file)
  if not file_exists(file) then return {} end
  lines = {}
  for line in io.lines(file) do 
    lines[#lines + 1] = line
  end
  return lines
end


-- Torch program that creates a simple AutoEncoder-style neural network, where output=input
print('\n\n @ @ @ @ @ @ START @ @ @ @ @ @ @ ');
print('Torch program that creates a simple AutoEncoder-style neural network, where output=input');

require 'os';
require 'lfs';

file = 'data.csv';

print('selected file: ' .. file);

chromRegions = {}
cellTypes = {}
dnaseIsignals = {}
cr = 0


chromRegion = {};
gm12878 = {};
h1hesc = {};
helas3 = {};
hepg2 = {};
huvec = {};
k562 = {};
dataset = {};

i = 0;
CellTypesNumber = 6

print('\n-- dataset building --');
-- data building

local file1 = io.open(file)
for line in file1:lines() do
  if i >= 1 then
        chromRegion[i-1], gm12878[i-1], h1hesc[i-1], helas3[i-1], hepg2[i-1], huvec[i-1], k562[i-1] = unpack(line:split(","))
    profile = torch.Tensor(CellTypesNumber);
    profile = {tonumber(gm12878[i-1]), tonumber(h1hesc[i-1]), tonumber(helas3[i-1]), tonumber(hepg2[i-1]), tonumber(huvec[i-1]), tonumber(k562[i-1])} 
    dnaseIsignals[i-1] = profile;
    profile = null;
  end
i = i + 1
end

chromRegionsNumber = #chromRegion+1
print('chromRegionsNumber '..chromRegionsNumber);

inputs=chromRegionsNumber; 
outputs=inputs; --

print(dnaseIsignals[0])
print(dnaseIsignals[chromRegionsNumber-1])

for i=1,chromRegionsNumber do   -- 15 times

    dataset[i] = {dnaseIsignals[i-1], dnaseIsignals[i-1]} 

    print(dataset[i]);
end
function dataset:size() return chromRegionsNumber end -- input dataset hgas 
function dataset:dim() return chromRegionsNumber end -- input dataset hgas 


HUs = 5;

-- Creation of the neural network
print('-- creation of the neural network --');
require "nn"
mlp=nn.Sequential();  -- make a multi-layer perceptron
mlp:add(nn.Linear(inputs,HUs)) -- adds a (input x HUs)  layer to the network
mlp:add(nn.Sigmoid());
mlp:add(nn.Linear(HUs,outputs)) -- adds a (HUs x outputs)  layer to the network
mlp:add(nn.Sigmoid()); -- Sigmoid also in output, Peter says

-- Training
print('-- training --');
criterion = nn.MSECriterion() 
trainer = nn.StochasticGradient(mlp, criterion)
trainer.learningRate = 0.01
trainer:train(dataset) --> THE PROBLEMS START HERE! :-(

-- Testing
print('-- testing --');
geneProfileChosen = 0;
x=torch.Tensor(inputs);   -- create a test example Tensor. Test element: first gene

-- training --  
# StochasticGradient: training  
/home/david/torch/install/bin/luajit: /home/david/torch/install/share/lua/5.1/nn/Linear.lua:34: attempt to call method 'dim' (a nil value)
stack traceback:
    /home/david/torch/install/share/lua/5.1/nn/Linear.lua:34: in function 'updateOutput'
    /home/david/torch/install/share/lua/5.1/nn/Sequential.lua:25: in function 'forward'
    ...id/torch/install/share/lua/5.1/nn/StochasticGradient.lua:35: in function 'train'
    autoencoder_chromatin_interactions.lua:103: in main chunk
    [C]: in function 'dofile'
    ...avid/torch/install/lib/luarocks/rocks/trepl/scm-1/bin/th:131: in main chunk
    [C]: at 0x00405330

