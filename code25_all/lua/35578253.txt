   net:add(SpatialConvolution(3, 96, 7, 7, 2, 2))
   net:add(nn.ReLU(true))
   net:add(SpatialMaxPooling(3, 3, 3, 3))
   net:add(SpatialConvolutionMM(96, 256, 7, 7, 1, 1))
   net:add(nn.ReLU(true))
   net:add(SpatialMaxPooling(2, 2, 2, 2))
   net:add(SpatialConvolutionMM(256, 512, 3, 3, 1, 1, 1, 1))
   net:add(nn.ReLU(true))
   net:add(SpatialConvolutionMM(512, 512, 3, 3, 1, 1, 1, 1))
   net:add(nn.ReLU(true))
   net:add(SpatialConvolutionMM(512, 1024, 3, 3, 1, 1, 1, 1))
   net:add(nn.ReLU(true))
   net:add(SpatialConvolutionMM(1024, 1024, 3, 3, 1, 1, 1, 1))
   net:add(nn.ReLU(true))
   net:add(SpatialMaxPooling(3, 3, 3, 3))
   net:add(SpatialConvolutionMM(1024, 4096, 5, 5, 1, 1))
   net:add(nn.ReLU(true))
   net:add(SpatialConvolutionMM(4096, 4096, 1, 1, 1, 1))
   net:add(nn.ReLU(true))
   net:add(SpatialConvolutionMM(4096, total_classes, 1, 1, 1, 1))
   net:add(nn.View(total_classes))
   net:add(nn.LogSoftMax())

   optimState = {
      learningRate = 1e-3,
      weightDecay = 0,
      momentum = 0,
      learningRateDecay = 1e-7
   }
   optimMethod = optim.sgd

optimMethod(feval, parameters, optimState)

-- 'feval' is the function with the forward and backward passes on the current batch
    parameters,gradParameters = net:getParameters()

