require 'torch'
require 'nn'

data = torch.Tensor( 16, 4 )
class = torch.Tensor( 16, 1 )

network = nn.Sequential()

network:add( nn.Linear( 4, 8 ) )
network:add( nn.ReLU() )
network:add( nn.Linear( 8, 2 ) )
network:add( nn.LogSoftMax() )

criterion = nn.ClassNLLCriterion()

for i = 1, 300 do
        prediction = network:forward( data )

        --print( "prediction: " .. tostring( prediction ) )
        --print( "class: " .. tostring( class ) )

        loss = criterion:forward( prediction, class )

        network:zeroGradParameters()

        grad = criterion:backward( prediction, class )
        network:backward( data, grad )

        network:updateParameters( 0.1 )
end

 0  0  0  0
 0  0  0  1
 0  0  1  0
 0  0  1  1
 0  1  0  0
 0  1  0  1
 0  1  1  0
 0  1  1  1
 1  0  0  0
 1  0  0  1
 1  0  1  0
 1  0  1  1
 1  1  0  0
 1  1  0  1
 1  1  1  0
 1  1  1  1
[torch.DoubleTensor of size 16x4]

 2
 2
 2
 2
 1
 1
 1
 1
 1
 1
 1
 1
 2
 2
 2
 2
[torch.DoubleTensor of size 16x1]

for k = 1, 300 do
for i = 1, 16 do
        prediction = network:forward( data[i] )

        --print( "prediction: " .. tostring( prediction ) )
        --print( "class: " .. tostring( class ) )

        loss = criterion:forward( prediction, class[i] )

        network:zeroGradParameters()

        grad = criterion:backward( prediction, class[i] )
        network:backward( data[i], grad )

        network:updateParameters( 0.1 )
end
end

-0.9008 -0.5213
-0.8591 -0.5508
-0.9107 -0.5146
-0.8002 -0.5965
-0.9244 -0.5055
-0.8581 -0.5516
-0.9174 -0.5101
-0.8040 -0.5934
-0.9509 -0.4884
-0.8409 -0.5644
-0.8922 -0.5272
-0.7737 -0.6186
-0.9422 -0.4939
-0.8405 -0.5648
-0.9012 -0.5210
-0.7820 -0.6116
[torch.DoubleTensor of size 16x2]

 2
 2
 2
 2
 1
 1
 1
 1
 1
 1
 1
 1
 2
 2
 2
 2
[torch.DoubleTensor of size 16x1]

