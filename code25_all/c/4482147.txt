#define CPU_PREFETCH(cache_line)            \
{ int* address = (int*) (cache_line);       \
    _asm mov edx, address                   \
    _asm prefetcht0[edx]                    \
}

#define CPU_GET_CYCLES(low)                 \
{                                           \
    _asm    rdtsc                           \
    _asm    mov dword ptr [low], eax        \
}

#define CPU_SYNC                            \
{                                           \
    _asm    mov eax, 0                      \
    _asm    cpuid                           \
}

#define CPU_CACHE_FLUSH(cache_line)         \
{ int* address = (int*) (cache_line);       \
    _asm mov edx, address                   \
    _asm clflush[edx]                       \
    _asm mfence                             \
}

#define CPU_PREFETCH(cache_line) \
{ \
    __asm__ __volatile__ ("prefetcht0 %0" : : "m" (*(int*)cache_line)); \
}

#define CPU_GET_CYCLES(low) \
{ \
    __asm__ __volatile__ ("rdtsc" : "=a" (low) : : "%edx"); \
}

#define CPU_SYNC \
{ \
    __asm__ __volatile__ ("cpuid" : : : "%eax", "%ebx", "%ecx", "%edx"); \
}

#define CPU_CACHE_FLUSH(cache_line) \
{ \
    __asm__ ("clflush %0; mfence" : : "m" (*(int*)cache_line)); \
}

