

\section{Math }\label{math}

Note: Functions taking \texttt{Tensor} arguments can also take anything
accepted by
\href{../../api_docs/python/framework.md\#convert_to_tensor}{\texttt{tf.convert\_to\_tensor}}.

\subsection{Contents}\label{contents}

\subsubsection{\texorpdfstring{\protect\hyperlink{AUTOGENERATED-math}{Math}}{Math}}\label{math-1}

\begin{itemize}
\tightlist
\item
  \protect\hyperlink{AUTOGENERATED-arithmetic-operators}{Arithmetic
  Operators}
\item
  \protect\hyperlink{add}{\texttt{tf.add(x,\ y,\ name=None)}}
\item
  \protect\hyperlink{sub}{\texttt{tf.sub(x,\ y,\ name=None)}}
\item
  \protect\hyperlink{mul}{\texttt{tf.mul(x,\ y,\ name=None)}}
\item
  \protect\hyperlink{div}{\texttt{tf.div(x,\ y,\ name=None)}}
\item
  \protect\hyperlink{mod}{\texttt{tf.mod(x,\ y,\ name=None)}}
\item
  \protect\hyperlink{AUTOGENERATED-basic-math-functions}{Basic Math
  Functions}
\item
  \protect\hyperlink{addux5fn}{\texttt{tf.add\_n(inputs,\ name=None)}}
\item
  \protect\hyperlink{abs}{\texttt{tf.abs(x,\ name=None)}}
\item
  \protect\hyperlink{neg}{\texttt{tf.neg(x,\ name=None)}}
\item
  \protect\hyperlink{sign}{\texttt{tf.sign(x,\ name=None)}}
\item
  \protect\hyperlink{inv}{\texttt{tf.inv(x,\ name=None)}}
\item
  \protect\hyperlink{square}{\texttt{tf.square(x,\ name=None)}}
\item
  \protect\hyperlink{round}{\texttt{tf.round(x,\ name=None)}}
\item
  \protect\hyperlink{sqrt}{\texttt{tf.sqrt(x,\ name=None)}}
\item
  \protect\hyperlink{rsqrt}{\texttt{tf.rsqrt(x,\ name=None)}}
\item
  \protect\hyperlink{pow}{\texttt{tf.pow(x,\ y,\ name=None)}}
\item
  \protect\hyperlink{exp}{\texttt{tf.exp(x,\ name=None)}}
\item
  \protect\hyperlink{log}{\texttt{tf.log(x,\ name=None)}}
\item
  \protect\hyperlink{ceil}{\texttt{tf.ceil(x,\ name=None)}}
\item
  \protect\hyperlink{floor}{\texttt{tf.floor(x,\ name=None)}}
\item
  \protect\hyperlink{maximum}{\texttt{tf.maximum(x,\ y,\ name=None)}}
\item
  \protect\hyperlink{minimum}{\texttt{tf.minimum(x,\ y,\ name=None)}}
\item
  \protect\hyperlink{cos}{\texttt{tf.cos(x,\ name=None)}}
\item
  \protect\hyperlink{sin}{\texttt{tf.sin(x,\ name=None)}}
\item
  \protect\hyperlink{AUTOGENERATED-matrix-math-functions}{Matrix Math
  Functions}
\item
  \protect\hyperlink{diag}{\texttt{tf.diag(diagonal,\ name=None)}}
\item
  \protect\hyperlink{transpose}{\texttt{tf.transpose(a,\ perm=None,\ name=\textquotesingle{}transpose\textquotesingle{})}}
\item
  \protect\hyperlink{matmul}{\texttt{tf.matmul(a,\ b,\ transpose\_a=False,\ transpose\_b=False,\ a\_is\_sparse=False,\ b\_is\_sparse=False,\ name=None)}}
\item
  \protect\hyperlink{batchux5fmatmul}{\texttt{tf.batch\_matmul(x,\ y,\ adj\_x=None,\ adj\_y=None,\ name=None)}}
\item
  \protect\hyperlink{matrixux5fdeterminant}{\texttt{tf.matrix\_determinant(input,\ name=None)}}
\item
  \protect\hyperlink{batchux5fmatrixux5fdeterminant}{\texttt{tf.batch\_matrix\_determinant(input,\ name=None)}}
\item
  \protect\hyperlink{matrixux5finverse}{\texttt{tf.matrix\_inverse(input,\ name=None)}}
\item
  \protect\hyperlink{batchux5fmatrixux5finverse}{\texttt{tf.batch\_matrix\_inverse(input,\ name=None)}}
\item
  \protect\hyperlink{cholesky}{\texttt{tf.cholesky(input,\ name=None)}}
\item
  \protect\hyperlink{batchux5fcholesky}{\texttt{tf.batch\_cholesky(input,\ name=None)}}
\item
  \protect\hyperlink{AUTOGENERATED-complex-number-functions}{Complex
  Number Functions}
\item
  \protect\hyperlink{complex}{\texttt{tf.complex(real,\ imag,\ name=None)}}
\item
  \protect\hyperlink{complexux5fabs}{\texttt{tf.complex\_abs(x,\ name=None)}}
\item
  \protect\hyperlink{conj}{\texttt{tf.conj(in\_,\ name=None)}}
\item
  \protect\hyperlink{imag}{\texttt{tf.imag(in\_,\ name=None)}}
\item
  \protect\hyperlink{real}{\texttt{tf.real(in\_,\ name=None)}}
\item
  \protect\hyperlink{AUTOGENERATED-reduction}{Reduction}
\item
  \protect\hyperlink{reduceux5fsum}{\texttt{tf.reduce\_sum(input\_tensor,\ reduction\_indices=None,\ keep\_dims=False,\ name=None)}}
\item
  \protect\hyperlink{reduceux5fprod}{\texttt{tf.reduce\_prod(input\_tensor,\ reduction\_indices=None,\ keep\_dims=False,\ name=None)}}
\item
  \protect\hyperlink{reduceux5fmin}{\texttt{tf.reduce\_min(input\_tensor,\ reduction\_indices=None,\ keep\_dims=False,\ name=None)}}
\item
  \protect\hyperlink{reduceux5fmax}{\texttt{tf.reduce\_max(input\_tensor,\ reduction\_indices=None,\ keep\_dims=False,\ name=None)}}
\item
  \protect\hyperlink{reduceux5fmean}{\texttt{tf.reduce\_mean(input\_tensor,\ reduction\_indices=None,\ keep\_dims=False,\ name=None)}}
\item
  \protect\hyperlink{reduceux5fall}{\texttt{tf.reduce\_all(input\_tensor,\ reduction\_indices=None,\ keep\_dims=False,\ name=None)}}
\item
  \protect\hyperlink{reduceux5fany}{\texttt{tf.reduce\_any(input\_tensor,\ reduction\_indices=None,\ keep\_dims=False,\ name=None)}}
\item
  \protect\hyperlink{accumulateux5fn}{\texttt{tf.accumulate\_n(inputs,\ shape=None,\ tensor\_dtype=None,\ name=None)}}
\item
  \protect\hyperlink{AUTOGENERATED-segmentation}{Segmentation}
\item
  \protect\hyperlink{segmentux5fsum}{\texttt{tf.segment\_sum(data,\ segment\_ids,\ name=None)}}
\item
  \protect\hyperlink{segmentux5fprod}{\texttt{tf.segment\_prod(data,\ segment\_ids,\ name=None)}}
\item
  \protect\hyperlink{segmentux5fmin}{\texttt{tf.segment\_min(data,\ segment\_ids,\ name=None)}}
\item
  \protect\hyperlink{segmentux5fmax}{\texttt{tf.segment\_max(data,\ segment\_ids,\ name=None)}}
\item
  \protect\hyperlink{segmentux5fmean}{\texttt{tf.segment\_mean(data,\ segment\_ids,\ name=None)}}
\item
  \protect\hyperlink{unsortedux5fsegmentux5fsum}{\texttt{tf.unsorted\_segment\_sum(data,\ segment\_ids,\ num\_segments,\ name=None)}}
\item
  \protect\hyperlink{sparseux5fsegmentux5fsum}{\texttt{tf.sparse\_segment\_sum(data,\ indices,\ segment\_ids,\ name=None)}}
\item
  \protect\hyperlink{sparseux5fsegmentux5fmean}{\texttt{tf.sparse\_segment\_mean(data,\ indices,\ segment\_ids,\ name=None)}}
\item
  \protect\hyperlink{AUTOGENERATED-sequence-comparison-and-indexing}{Sequence
  Comparison and Indexing}
\item
  \protect\hyperlink{argmin}{\texttt{tf.argmin(input,\ dimension,\ name=None)}}
\item
  \protect\hyperlink{argmax}{\texttt{tf.argmax(input,\ dimension,\ name=None)}}
\item
  \protect\hyperlink{listdiff}{\texttt{tf.listdiff(x,\ y,\ name=None)}}
\item
  \protect\hyperlink{where}{\texttt{tf.where(input,\ name=None)}}
\item
  \protect\hyperlink{unique}{\texttt{tf.unique(x,\ name=None)}}
\item
  \protect\hyperlink{editux5fdistance}{\texttt{tf.edit\_distance(hypothesis,\ truth,\ normalize=True,\ name=\textquotesingle{}edit\_distance\textquotesingle{})}}
\item
  \protect\hyperlink{invertux5fpermutation}{\texttt{tf.invert\_permutation(x,\ name=None)}}
\end{itemize}

\subsection{Arithmetic Operators }\label{arithmetic-operators}

TensorFlow provides several operations that you can use to add basic
arithmetic operators to your graph.

\begin{center}\rule{0.5\linewidth}{\linethickness}\end{center}

\subsubsection{\texorpdfstring{\texttt{tf.add(x,\ y,\ name=None)}
}{tf.add(x, y, name=None) }}\label{tf.addx-y-namenone}

Returns x + y element-wise.

\emph{NOTE}: Add supports broadcasting. AddN does not.

\subparagraph{Args: }\label{args}

\begin{itemize}
\tightlist
\item
  \texttt{x}: A \texttt{Tensor}. Must be one of the following types:
  \texttt{float32}, \texttt{float64}, \texttt{int8}, \texttt{int16},
  \texttt{int32}, \texttt{complex64}, \texttt{int64}.
\item
  \texttt{y}: A \texttt{Tensor}. Must have the same type as \texttt{x}.
\item
  \texttt{name}: A name for the operation (optional).
\end{itemize}

\subparagraph{Returns: }\label{returns}

A \texttt{Tensor}. Has the same type as \texttt{x}.

\begin{center}\rule{0.5\linewidth}{\linethickness}\end{center}

\subsubsection{\texorpdfstring{\texttt{tf.sub(x,\ y,\ name=None)}
}{tf.sub(x, y, name=None) }}\label{tf.subx-y-namenone}

Returns x - y element-wise.

\subparagraph{Args: }\label{args-1}

\begin{itemize}
\tightlist
\item
  \texttt{x}: A \texttt{Tensor}. Must be one of the following types:
  \texttt{float32}, \texttt{float64}, \texttt{int32},
  \texttt{complex64}, \texttt{int64}.
\item
  \texttt{y}: A \texttt{Tensor}. Must have the same type as \texttt{x}.
\item
  \texttt{name}: A name for the operation (optional).
\end{itemize}

\subparagraph{Returns: }\label{returns-1}

A \texttt{Tensor}. Has the same type as \texttt{x}.

\begin{center}\rule{0.5\linewidth}{\linethickness}\end{center}

\subsubsection{\texorpdfstring{\texttt{tf.mul(x,\ y,\ name=None)}
}{tf.mul(x, y, name=None) }}\label{tf.mulx-y-namenone}

Returns x * y element-wise.

\subparagraph{Args: }\label{args-2}

\begin{itemize}
\tightlist
\item
  \texttt{x}: A \texttt{Tensor}. Must be one of the following types:
  \texttt{float32}, \texttt{float64}, \texttt{int8}, \texttt{int16},
  \texttt{int32}, \texttt{complex64}, \texttt{int64}.
\item
  \texttt{y}: A \texttt{Tensor}. Must have the same type as \texttt{x}.
\item
  \texttt{name}: A name for the operation (optional).
\end{itemize}

\subparagraph{Returns: }\label{returns-2}

A \texttt{Tensor}. Has the same type as \texttt{x}.

\begin{center}\rule{0.5\linewidth}{\linethickness}\end{center}

\subsubsection{\texorpdfstring{\texttt{tf.div(x,\ y,\ name=None)}
}{tf.div(x, y, name=None) }}\label{tf.divx-y-namenone}

Returns x / y element-wise.

\subparagraph{Args: }\label{args-3}

\begin{itemize}
\tightlist
\item
  \texttt{x}: A \texttt{Tensor}. Must be one of the following types:
  \texttt{float32}, \texttt{float64}, \texttt{int32},
  \texttt{complex64}, \texttt{int64}.
\item
  \texttt{y}: A \texttt{Tensor}. Must have the same type as \texttt{x}.
\item
  \texttt{name}: A name for the operation (optional).
\end{itemize}

\subparagraph{Returns: }\label{returns-3}

A \texttt{Tensor}. Has the same type as \texttt{x}.

\begin{center}\rule{0.5\linewidth}{\linethickness}\end{center}

\subsubsection{\texorpdfstring{\texttt{tf.mod(x,\ y,\ name=None)}
}{tf.mod(x, y, name=None) }}\label{tf.modx-y-namenone}

Returns element-wise remainder of division.

\subparagraph{Args: }\label{args-4}

\begin{itemize}
\tightlist
\item
  \texttt{x}: A \texttt{Tensor}. Must be one of the following types:
  \texttt{int32}, \texttt{int64}, \texttt{float32}, \texttt{float64}.
\item
  \texttt{y}: A \texttt{Tensor}. Must have the same type as \texttt{x}.
\item
  \texttt{name}: A name for the operation (optional).
\end{itemize}

\subparagraph{Returns: }\label{returns-4}

A \texttt{Tensor}. Has the same type as \texttt{x}.

\subsection{Basic Math Functions }\label{basic-math-functions}

TensorFlow provides several operations that you can use to add basic
mathematical functions to your graph.

\begin{center}\rule{0.5\linewidth}{\linethickness}\end{center}

\subsubsection{\texorpdfstring{\texttt{tf.add\_n(inputs,\ name=None)}
}{tf.add\_n(inputs, name=None) }}\label{tf.addux5fninputs-namenone}

Add all input tensors element wise.

\subparagraph{Args: }\label{args-5}

\begin{itemize}
\tightlist
\item
  \texttt{inputs}: A list of at least 1 \texttt{Tensor} objects of the
  same type in: \texttt{float32}, \texttt{float64}, \texttt{int64},
  \texttt{int32}, \texttt{uint8}, \texttt{int16}, \texttt{int8},
  \texttt{complex64}, \texttt{qint8}, \texttt{quint8}, \texttt{qint32}.
  Must all be the same size and shape.
\item
  \texttt{name}: A name for the operation (optional).
\end{itemize}

\subparagraph{Returns: }\label{returns-5}

A \texttt{Tensor}. Has the same type as \texttt{inputs}.

\begin{center}\rule{0.5\linewidth}{\linethickness}\end{center}

\subsubsection{\texorpdfstring{\texttt{tf.abs(x,\ name=None)}
}{tf.abs(x, name=None) }}\label{tf.absx-namenone}

Computes the absolute value of a tensor.

Given a tensor of real numbers \texttt{x}, this operation returns a
tensor containing the absolute value of each element in \texttt{x}. For
example, if x is an input element and y is an output element, this
operation computes \textbackslash{}(y =
\textbar{}x\textbar{}\textbackslash{}).

See \protect\hyperlink{tfux5fcomplexux5fabs}{\texttt{tf.complex\_abs()}}
to compute the absolute value of a complex number.

\subparagraph{Args: }\label{args-6}

\begin{itemize}
\tightlist
\item
  \texttt{x}: A \texttt{Tensor} of type \texttt{float}, \texttt{double},
  \texttt{int32}, or \texttt{int64}.
\item
  \texttt{name}: A name for the operation (optional).
\end{itemize}

\subparagraph{Returns: }\label{returns-6}

A \texttt{Tensor} the same size and type as \texttt{x} with absolute
values.

\begin{center}\rule{0.5\linewidth}{\linethickness}\end{center}

\subsubsection{\texorpdfstring{\texttt{tf.neg(x,\ name=None)}
}{tf.neg(x, name=None) }}\label{tf.negx-namenone}

Computes numerical negative value element-wise.

I.e., \textbackslash{}(y = -x\textbackslash{}).

\subparagraph{Args: }\label{args-7}

\begin{itemize}
\tightlist
\item
  \texttt{x}: A \texttt{Tensor}. Must be one of the following types:
  \texttt{float32}, \texttt{float64}, \texttt{int32},
  \texttt{complex64}, \texttt{int64}.
\item
  \texttt{name}: A name for the operation (optional).
\end{itemize}

\subparagraph{Returns: }\label{returns-7}

A \texttt{Tensor}. Has the same type as \texttt{x}.

\begin{center}\rule{0.5\linewidth}{\linethickness}\end{center}

\subsubsection{\texorpdfstring{\texttt{tf.sign(x,\ name=None)}
}{tf.sign(x, name=None) }}\label{tf.signx-namenone}

Returns an element-wise indication of the sign of a number.

y = sign(x) = -1 if x \textless{} 0; 0 if x == 0; 1 if x \textgreater{}
0.

\subparagraph{Args: }\label{args-8}

\begin{itemize}
\tightlist
\item
  \texttt{x}: A \texttt{Tensor}. Must be one of the following types:
  \texttt{float32}, \texttt{float64}, \texttt{int32}, \texttt{int64}.
\item
  \texttt{name}: A name for the operation (optional).
\end{itemize}

\subparagraph{Returns: }\label{returns-8}

A \texttt{Tensor}. Has the same type as \texttt{x}.

\begin{center}\rule{0.5\linewidth}{\linethickness}\end{center}

\subsubsection{\texorpdfstring{\texttt{tf.inv(x,\ name=None)}
}{tf.inv(x, name=None) }}\label{tf.invx-namenone}

Computes the reciprocal of x element-wise.

I.e., \textbackslash{}(y = 1 / x\textbackslash{}).

\subparagraph{Args: }\label{args-9}

\begin{itemize}
\tightlist
\item
  \texttt{x}: A \texttt{Tensor}. Must be one of the following types:
  \texttt{float32}, \texttt{float64}, \texttt{int32},
  \texttt{complex64}, \texttt{int64}.
\item
  \texttt{name}: A name for the operation (optional).
\end{itemize}

\subparagraph{Returns: }\label{returns-9}

A \texttt{Tensor}. Has the same type as \texttt{x}.

\begin{center}\rule{0.5\linewidth}{\linethickness}\end{center}

\subsubsection{\texorpdfstring{\texttt{tf.square(x,\ name=None)}
}{tf.square(x, name=None) }}\label{tf.squarex-namenone}

Computes square of x element-wise.

I.e., \textbackslash{}(y = x * x = x\^{}2\textbackslash{}).

\subparagraph{Args: }\label{args-10}

\begin{itemize}
\tightlist
\item
  \texttt{x}: A \texttt{Tensor}. Must be one of the following types:
  \texttt{float32}, \texttt{float64}, \texttt{int32},
  \texttt{complex64}, \texttt{int64}.
\item
  \texttt{name}: A name for the operation (optional).
\end{itemize}

\subparagraph{Returns: }\label{returns-10}

A \texttt{Tensor}. Has the same type as \texttt{x}.

\begin{center}\rule{0.5\linewidth}{\linethickness}\end{center}

\subsubsection{\texorpdfstring{\texttt{tf.round(x,\ name=None)}
}{tf.round(x, name=None) }}\label{tf.roundx-namenone}

Rounds the values of a tensor to the nearest integer, element-wise.

For example:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# 'a' is [0.9, 2.5, 2.3, -4.4]}
\NormalTok{tf.}\BuiltInTok{round}\NormalTok{(a) }\OperatorTok{==>} \NormalTok{[ }\FloatTok{1.0}\NormalTok{, }\FloatTok{3.0}\NormalTok{, }\FloatTok{2.0}\NormalTok{, }\OperatorTok{-}\FloatTok{4.0} \NormalTok{]}
\end{Highlighting}
\end{Shaded}

\subparagraph{Args: }\label{args-11}

\begin{itemize}
\tightlist
\item
  \texttt{x}: A \texttt{Tensor} of type \texttt{float} or
  \texttt{double}.
\item
  \texttt{name}: A name for the operation (optional).
\end{itemize}

\subparagraph{Returns: }\label{returns-11}

A \texttt{Tensor} of same shape and type as \texttt{x}.

\begin{center}\rule{0.5\linewidth}{\linethickness}\end{center}

\subsubsection{\texorpdfstring{\texttt{tf.sqrt(x,\ name=None)}
}{tf.sqrt(x, name=None) }}\label{tf.sqrtx-namenone}

Computes square root of x element-wise.

I.e., \textbackslash{}(y = \sqrt{x} = x\^{}\{1/2\}\textbackslash{}).

\subparagraph{Args: }\label{args-12}

\begin{itemize}
\tightlist
\item
  \texttt{x}: A \texttt{Tensor}. Must be one of the following types:
  \texttt{float32}, \texttt{float64}, \texttt{int32},
  \texttt{complex64}, \texttt{int64}.
\item
  \texttt{name}: A name for the operation (optional).
\end{itemize}

\subparagraph{Returns: }\label{returns-12}

A \texttt{Tensor}. Has the same type as \texttt{x}.

\begin{center}\rule{0.5\linewidth}{\linethickness}\end{center}

\subsubsection{\texorpdfstring{\texttt{tf.rsqrt(x,\ name=None)}
}{tf.rsqrt(x, name=None) }}\label{tf.rsqrtx-namenone}

Computes reciprocal of square root of x element-wise.

I.e., \textbackslash{}(y = 1 / \sqrt{x}\textbackslash{}).

\subparagraph{Args: }\label{args-13}

\begin{itemize}
\tightlist
\item
  \texttt{x}: A \texttt{Tensor}. Must be one of the following types:
  \texttt{float32}, \texttt{float64}, \texttt{int32},
  \texttt{complex64}, \texttt{int64}.
\item
  \texttt{name}: A name for the operation (optional).
\end{itemize}

\subparagraph{Returns: }\label{returns-13}

A \texttt{Tensor}. Has the same type as \texttt{x}.

\begin{center}\rule{0.5\linewidth}{\linethickness}\end{center}

\subsubsection{\texorpdfstring{\texttt{tf.pow(x,\ y,\ name=None)}
}{tf.pow(x, y, name=None) }}\label{tf.powx-y-namenone}

Computes the power of one value to another.

Given a tensor \texttt{x} and a tensor \texttt{y}, this operation
computes \textbackslash{}(x\^{}y\textbackslash{}) for corresponding
elements in \texttt{x} and \texttt{y}. For example:

\begin{verbatim}
# tensor 'x' is [[2, 2]], [3, 3]]
# tensor 'y' is [[8, 16], [2, 3]]
tf.pow(x, y) ==> [[256, 65536], [9, 27]]
\end{verbatim}

\subparagraph{Args: }\label{args-14}

\begin{itemize}
\tightlist
\item
  \texttt{x}: A \texttt{Tensor} of type \texttt{float}, \texttt{double},
  \texttt{int32}, \texttt{complex64}, or \texttt{int64}.
\item
  \texttt{y}: A \texttt{Tensor} of type \texttt{float}, \texttt{double},
  \texttt{int32}, \texttt{complex64}, or \texttt{int64}.
\item
  \texttt{name}: A name for the operation (optional).
\end{itemize}

\subparagraph{Returns: }\label{returns-14}

A \texttt{Tensor}.

\begin{center}\rule{0.5\linewidth}{\linethickness}\end{center}

\subsubsection{\texorpdfstring{\texttt{tf.exp(x,\ name=None)}
}{tf.exp(x, name=None) }}\label{tf.expx-namenone}

Computes exponential of x element-wise. \textbackslash{}(y =
e\^{}x\textbackslash{}).

\subparagraph{Args: }\label{args-15}

\begin{itemize}
\tightlist
\item
  \texttt{x}: A \texttt{Tensor}. Must be one of the following types:
  \texttt{float32}, \texttt{float64}, \texttt{int32},
  \texttt{complex64}, \texttt{int64}.
\item
  \texttt{name}: A name for the operation (optional).
\end{itemize}

\subparagraph{Returns: }\label{returns-15}

A \texttt{Tensor}. Has the same type as \texttt{x}.

\begin{center}\rule{0.5\linewidth}{\linethickness}\end{center}

\subsubsection{\texorpdfstring{\texttt{tf.log(x,\ name=None)}
}{tf.log(x, name=None) }}\label{tf.logx-namenone}

Computes natural logrithm of x element-wise.

I.e., \textbackslash{}(y = \log\_e x\textbackslash{}).

\subparagraph{Args: }\label{args-16}

\begin{itemize}
\tightlist
\item
  \texttt{x}: A \texttt{Tensor}. Must be one of the following types:
  \texttt{float32}, \texttt{float64}, \texttt{int32},
  \texttt{complex64}, \texttt{int64}.
\item
  \texttt{name}: A name for the operation (optional).
\end{itemize}

\subparagraph{Returns: }\label{returns-16}

A \texttt{Tensor}. Has the same type as \texttt{x}.

\begin{center}\rule{0.5\linewidth}{\linethickness}\end{center}

\subsubsection{\texorpdfstring{\texttt{tf.ceil(x,\ name=None)}
}{tf.ceil(x, name=None) }}\label{tf.ceilx-namenone}

Returns element-wise smallest integer in not less than x.

\subparagraph{Args: }\label{args-17}

\begin{itemize}
\tightlist
\item
  \texttt{x}: A \texttt{Tensor}. Must be one of the following types:
  \texttt{float32}, \texttt{float64}.
\item
  \texttt{name}: A name for the operation (optional).
\end{itemize}

\subparagraph{Returns: }\label{returns-17}

A \texttt{Tensor}. Has the same type as \texttt{x}.

\begin{center}\rule{0.5\linewidth}{\linethickness}\end{center}

\subsubsection{\texorpdfstring{\texttt{tf.floor(x,\ name=None)}
}{tf.floor(x, name=None) }}\label{tf.floorx-namenone}

Returns element-wise largest integer not greater than x.

\subparagraph{Args: }\label{args-18}

\begin{itemize}
\tightlist
\item
  \texttt{x}: A \texttt{Tensor}. Must be one of the following types:
  \texttt{float32}, \texttt{float64}.
\item
  \texttt{name}: A name for the operation (optional).
\end{itemize}

\subparagraph{Returns: }\label{returns-18}

A \texttt{Tensor}. Has the same type as \texttt{x}.

\begin{center}\rule{0.5\linewidth}{\linethickness}\end{center}

\subsubsection{\texorpdfstring{\texttt{tf.maximum(x,\ y,\ name=None)}
}{tf.maximum(x, y, name=None) }}\label{tf.maximumx-y-namenone}

Returns the max of x and y (i.e.~x \textgreater{} y ? x : y)
element-wise, broadcasts.

\subparagraph{Args: }\label{args-19}

\begin{itemize}
\tightlist
\item
  \texttt{x}: A \texttt{Tensor}. Must be one of the following types:
  \texttt{float32}, \texttt{float64}, \texttt{int32}, \texttt{int64}.
\item
  \texttt{y}: A \texttt{Tensor}. Must have the same type as \texttt{x}.
\item
  \texttt{name}: A name for the operation (optional).
\end{itemize}

\subparagraph{Returns: }\label{returns-19}

A \texttt{Tensor}. Has the same type as \texttt{x}.

\begin{center}\rule{0.5\linewidth}{\linethickness}\end{center}

\subsubsection{\texorpdfstring{\texttt{tf.minimum(x,\ y,\ name=None)}
}{tf.minimum(x, y, name=None) }}\label{tf.minimumx-y-namenone}

Returns the min of x and y (i.e.~x \textless{} y ? x : y) element-wise,
broadcasts.

\subparagraph{Args: }\label{args-20}

\begin{itemize}
\tightlist
\item
  \texttt{x}: A \texttt{Tensor}. Must be one of the following types:
  \texttt{float32}, \texttt{float64}, \texttt{int32}, \texttt{int64}.
\item
  \texttt{y}: A \texttt{Tensor}. Must have the same type as \texttt{x}.
\item
  \texttt{name}: A name for the operation (optional).
\end{itemize}

\subparagraph{Returns: }\label{returns-20}

A \texttt{Tensor}. Has the same type as \texttt{x}.

\begin{center}\rule{0.5\linewidth}{\linethickness}\end{center}

\subsubsection{\texorpdfstring{\texttt{tf.cos(x,\ name=None)}
}{tf.cos(x, name=None) }}\label{tf.cosx-namenone}

Computes cos of x element-wise.

\subparagraph{Args: }\label{args-21}

\begin{itemize}
\tightlist
\item
  \texttt{x}: A \texttt{Tensor}. Must be one of the following types:
  \texttt{float32}, \texttt{float64}, \texttt{int32},
  \texttt{complex64}, \texttt{int64}.
\item
  \texttt{name}: A name for the operation (optional).
\end{itemize}

\subparagraph{Returns: }\label{returns-21}

A \texttt{Tensor}. Has the same type as \texttt{x}.

\begin{center}\rule{0.5\linewidth}{\linethickness}\end{center}

\subsubsection{\texorpdfstring{\texttt{tf.sin(x,\ name=None)}
}{tf.sin(x, name=None) }}\label{tf.sinx-namenone}

Computes sin of x element-wise.

\subparagraph{Args: }\label{args-22}

\begin{itemize}
\tightlist
\item
  \texttt{x}: A \texttt{Tensor}. Must be one of the following types:
  \texttt{float32}, \texttt{float64}, \texttt{int32},
  \texttt{complex64}, \texttt{int64}.
\item
  \texttt{name}: A name for the operation (optional).
\end{itemize}

\subparagraph{Returns: }\label{returns-22}

A \texttt{Tensor}. Has the same type as \texttt{x}.

\subsection{Matrix Math Functions }\label{matrix-math-functions}

TensorFlow provides several operations that you can use to add basic
mathematical functions for matrices to your graph.

\begin{center}\rule{0.5\linewidth}{\linethickness}\end{center}

\subsubsection{\texorpdfstring{\texttt{tf.diag(diagonal,\ name=None)}
}{tf.diag(diagonal, name=None) }}\label{tf.diagdiagonal-namenone}

Returns a diagonal tensor with a given diagonal values.

Given a \texttt{diagonal}, this operation returns a tensor with the
\texttt{diagonal} and everything else padded with zeros. The diagonal is
computed as follows:

Assume \texttt{diagonal} has dimensions {[}D1,\ldots{}, Dk{]}, then the
output is a tensor of rank 2k with dimensions {[}D1,\ldots{}, Dk,
D1,\ldots{}, Dk{]} where:

\texttt{output{[}i1,...,\ ik,\ i1,...,\ ik{]}\ =\ diagonal{[}i1,\ ...,\ ik{]}}
and 0 everywhere else.

For example:

\begin{verbatim}
# 'diagonal' is [1, 2, 3, 4]
tf.diag(diagonal) ==> [[1, 0, 0, 0]
                       [0, 2, 0, 0]
                       [0, 0, 3, 0]
                       [0, 0, 0, 4]]
\end{verbatim}

\subparagraph{Args: }\label{args-23}

\begin{itemize}
\tightlist
\item
  \texttt{diagonal}: A \texttt{Tensor}. Must be one of the following
  types: \texttt{float32}, \texttt{float64}, \texttt{int32},
  \texttt{int64}. Rank k tensor where k is at most 3.
\item
  \texttt{name}: A name for the operation (optional).
\end{itemize}

\subparagraph{Returns: }\label{returns-23}

A \texttt{Tensor}. Has the same type as \texttt{diagonal}.

\begin{center}\rule{0.5\linewidth}{\linethickness}\end{center}

\subsubsection{\texorpdfstring{\texttt{tf.transpose(a,\ perm=None,\ name=\textquotesingle{}transpose\textquotesingle{})}
}{tf.transpose(a, perm=None, name='transpose') }}\label{tf.transposea-permnone-nametranspose}

Transposes \texttt{a}. Permutes the dimensions according to
\texttt{perm}.

The returned tensor's dimension i will correspond to the input dimension
\texttt{perm{[}i{]}}. If \texttt{perm} is not given, it is set to
(n-1\ldots{}0), where n is the rank of the input tensor. Hence by
default, this operation performs a regular matrix transpose on 2-D input
Tensors.

For example:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# 'x' is [[1 2 3]}
\CommentTok{#         [4 5 6]]}
\NormalTok{tf.transpose(x) }\OperatorTok{==>} \NormalTok{[[}\DecValTok{1} \DecValTok{4}\NormalTok{]}
                     \NormalTok{[}\DecValTok{2} \DecValTok{5}\NormalTok{]}
                     \NormalTok{[}\DecValTok{3} \DecValTok{6}\NormalTok{]]}

\CommentTok{# Equivalently}
\NormalTok{tf.transpose(x perm}\OperatorTok{=}\NormalTok{[}\DecValTok{0}\NormalTok{, }\DecValTok{1}\NormalTok{]) }\OperatorTok{==>} \NormalTok{[[}\DecValTok{1} \DecValTok{4}\NormalTok{]}
                                 \NormalTok{[}\DecValTok{2} \DecValTok{5}\NormalTok{]}
                                 \NormalTok{[}\DecValTok{3} \DecValTok{6}\NormalTok{]]}

\CommentTok{# 'perm' is more useful for n-dimensional tensors, for n > 2}
\CommentTok{# 'x' is   [[[1  2  3]}
\CommentTok{#            [4  5  6]]}
\CommentTok{#           [[7  8  9]}
\CommentTok{#            [10 11 12]]]}
\CommentTok{# Take the transpose of the matrices in dimension-0}
\NormalTok{tf.transpose(b, perm}\OperatorTok{=}\NormalTok{[}\DecValTok{0}\NormalTok{, }\DecValTok{2}\NormalTok{, }\DecValTok{1}\NormalTok{]) }\OperatorTok{==>} \NormalTok{[[[}\DecValTok{1}  \DecValTok{4}\NormalTok{]}
                                      \NormalTok{[}\DecValTok{2}  \DecValTok{5}\NormalTok{]}
                                      \NormalTok{[}\DecValTok{3}  \DecValTok{6}\NormalTok{]]}

                                     \NormalTok{[[}\DecValTok{7} \DecValTok{10}\NormalTok{]}
                                      \NormalTok{[}\DecValTok{8} \DecValTok{11}\NormalTok{]}
                                      \NormalTok{[}\DecValTok{9} \DecValTok{12}\NormalTok{]]]}
\end{Highlighting}
\end{Shaded}

\subparagraph{Args: }\label{args-24}

\begin{itemize}
\tightlist
\item
  \texttt{a}: A \texttt{Tensor}.
\item
  \texttt{perm}: A permutation of the dimensions of \texttt{a}.
\item
  \texttt{name}: A name for the operation (optional).
\end{itemize}

\subparagraph{Returns: }\label{returns-24}

A transposed \texttt{Tensor}.

\begin{center}\rule{0.5\linewidth}{\linethickness}\end{center}

\subsubsection{\texorpdfstring{\texttt{tf.matmul(a,\ b,\ transpose\_a=False,\ transpose\_b=False,\ a\_is\_sparse=False,\ b\_is\_sparse=False,\ name=None)}
}{tf.matmul(a, b, transpose\_a=False, transpose\_b=False, a\_is\_sparse=False, b\_is\_sparse=False, name=None) }}\label{tf.matmula-b-transposeux5fafalse-transposeux5fbfalse-aux5fisux5fsparsefalse-bux5fisux5fsparsefalse-namenone}

Multiplies matrix \texttt{a} by matrix \texttt{b}, producing \texttt{a}
* \texttt{b}.

The inputs must be two-dimensional matrices, with matching inner
dimensions, possibly after transposition.

Both matrices must be of the same type. The supported types are:
\texttt{float}, \texttt{double}, \texttt{int32}, \texttt{complex64}.

Either matrix can be transposed on the fly by setting the corresponding
flag to \texttt{True}. This is \texttt{False} by default.

If one or both of the matrices contain a lot of zeros, a more efficient
multiplication algorithm can be used by setting the corresponding
\texttt{a\_is\_sparse} or \texttt{b\_is\_sparse} flag to \texttt{True}.
These are \texttt{False} by default.

For example:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# 2-D tensor `a`}
\NormalTok{a }\OperatorTok{=} \NormalTok{tf.constant([}\DecValTok{1}\NormalTok{, }\DecValTok{2}\NormalTok{, }\DecValTok{3}\NormalTok{, }\DecValTok{4}\NormalTok{, }\DecValTok{5}\NormalTok{, }\DecValTok{6}\NormalTok{], shape}\OperatorTok{=}\NormalTok{[}\DecValTok{2}\NormalTok{, }\DecValTok{3}\NormalTok{]) }\OperatorTok{=>} \NormalTok{[[}\DecValTok{1}\NormalTok{. }\DecValTok{2}\NormalTok{. }\DecValTok{3}\NormalTok{.]}
                                                      \NormalTok{[}\DecValTok{4}\NormalTok{. }\DecValTok{5}\NormalTok{. }\DecValTok{6}\NormalTok{.]]}
\CommentTok{# 2-D tensor `b`}
\NormalTok{b }\OperatorTok{=} \NormalTok{tf.constant([}\DecValTok{7}\NormalTok{, }\DecValTok{8}\NormalTok{, }\DecValTok{9}\NormalTok{, }\DecValTok{10}\NormalTok{, }\DecValTok{11}\NormalTok{, }\DecValTok{12}\NormalTok{], shape}\OperatorTok{=}\NormalTok{[}\DecValTok{3}\NormalTok{, }\DecValTok{2}\NormalTok{]) }\OperatorTok{=>} \NormalTok{[[}\DecValTok{7}\NormalTok{. }\DecValTok{8}\NormalTok{.]}
                                                         \NormalTok{[}\DecValTok{9}\NormalTok{. }\DecValTok{10}\NormalTok{.]}
                                                         \NormalTok{[}\DecValTok{11}\NormalTok{. }\DecValTok{12}\NormalTok{.]]}
\NormalTok{c }\OperatorTok{=} \NormalTok{tf.matmul(a, b) }\OperatorTok{=>} \NormalTok{[[}\DecValTok{58} \DecValTok{64}\NormalTok{]}
                        \NormalTok{[}\DecValTok{139} \DecValTok{154}\NormalTok{]]}
\end{Highlighting}
\end{Shaded}

\subparagraph{Args: }\label{args-25}

\begin{itemize}
\tightlist
\item
  \texttt{a}: \texttt{Tensor} of type \texttt{float}, \texttt{double},
  \texttt{int32} or \texttt{complex64}.
\item
  \texttt{b}: \texttt{Tensor} with same type as \texttt{a}.
\item
  \texttt{transpose\_a}: If \texttt{True}, \texttt{a} is transposed
  before multiplication.
\item
  \texttt{transpose\_b}: If \texttt{True}, \texttt{b} is transposed
  before multiplication.
\item
  \texttt{a\_is\_sparse}: If \texttt{True}, \texttt{a} is treated as a
  sparse matrix.
\item
  \texttt{b\_is\_sparse}: If \texttt{True}, \texttt{b} is treated as a
  sparse matrix.
\item
  \texttt{name}: Name for the operation (optional).
\end{itemize}

\subparagraph{Returns: }\label{returns-25}

A \texttt{Tensor} of the same type as \texttt{a}.

\begin{center}\rule{0.5\linewidth}{\linethickness}\end{center}

\subsubsection{\texorpdfstring{\texttt{tf.batch\_matmul(x,\ y,\ adj\_x=None,\ adj\_y=None,\ name=None)}
}{tf.batch\_matmul(x, y, adj\_x=None, adj\_y=None, name=None) }}\label{tf.batchux5fmatmulx-y-adjux5fxnone-adjux5fynone-namenone}

Multiplies slices of two tensors in batches.

Multiplies all slices of \texttt{Tensor} \texttt{x} and \texttt{y} (each
slice can be viewed as an element of a batch), and arranges the
individual results in a single output tensor of the same batch size.
Each of the individual slices can optionally be adjointed (to adjoint a
matrix means to transpose and conjugate it) before multiplication by
setting the \texttt{adj\_x} or \texttt{adj\_y} flag to \texttt{True},
which are by default \texttt{False}.

The input tensors \texttt{x} and \texttt{y} are 3-D or higher with shape
\texttt{{[}...,\ r\_x,\ c\_x{]}} and \texttt{{[}...,\ r\_y,\ c\_y{]}}.

The output tensor is 3-D or higher with shape
\texttt{{[}...,\ r\_o,\ c\_o{]}}, where:

\begin{verbatim}
r_o = c_x if adj_x else r_x
c_o = r_y if adj_y else c_y
\end{verbatim}

It is computed as:

\begin{verbatim}
out[..., :, :] = matrix(x[..., :, :]) * matrix(y[..., :, :])
\end{verbatim}

\subparagraph{Args: }\label{args-26}

\begin{itemize}
\tightlist
\item
  \texttt{x}: A \texttt{Tensor}. Must be one of the following types:
  \texttt{float32}, \texttt{float64}, \texttt{int32},
  \texttt{complex64}. 3-D or higher with shape
  \texttt{{[}...,\ r\_x,\ c\_x{]}}.
\item
  \texttt{y}: A \texttt{Tensor}. Must have the same type as \texttt{x}.
  3-D or higher with shape \texttt{{[}...,\ r\_y,\ c\_y{]}}.
\item
  \texttt{adj\_x}: An optional \texttt{bool}. Defaults to
  \texttt{False}. If \texttt{True}, adjoint the slices of \texttt{x}.
  Defaults to \texttt{False}.
\item
  \texttt{adj\_y}: An optional \texttt{bool}. Defaults to
  \texttt{False}. If \texttt{True}, adjoint the slices of \texttt{y}.
  Defaults to \texttt{False}.
\item
  \texttt{name}: A name for the operation (optional).
\end{itemize}

\subparagraph{Returns: }\label{returns-26}

A \texttt{Tensor}. Has the same type as \texttt{x}. 3-D or higher with
shape \texttt{{[}...,\ r\_o,\ c\_o{]}}

\begin{center}\rule{0.5\linewidth}{\linethickness}\end{center}

\subsubsection{\texorpdfstring{\texttt{tf.matrix\_determinant(input,\ name=None)}
}{tf.matrix\_determinant(input, name=None) }}\label{tf.matrixux5fdeterminantinput-namenone}

Calculates the determinant of a square matrix.

\subparagraph{Args: }\label{args-27}

\begin{itemize}
\tightlist
\item
  \texttt{input}: A \texttt{Tensor}. Must be one of the following types:
  \texttt{float32}, \texttt{float64}. A tensor of shape
  \texttt{{[}M,\ M{]}}.
\item
  \texttt{name}: A name for the operation (optional).
\end{itemize}

\subparagraph{Returns: }\label{returns-27}

A \texttt{Tensor}. Has the same type as \texttt{input}. A scalar, equal
to the determinant of the input.

\begin{center}\rule{0.5\linewidth}{\linethickness}\end{center}

\subsubsection{\texorpdfstring{\texttt{tf.batch\_matrix\_determinant(input,\ name=None)}
}{tf.batch\_matrix\_determinant(input, name=None) }}\label{tf.batchux5fmatrixux5fdeterminantinput-namenone}

Calculates the determinants for a batch of square matrices.

The input is a tensor of shape \texttt{{[}...,\ M,\ M{]}} whose
inner-most 2 dimensions form square matrices. The output is a 1-D tensor
containing the determinants for all input submatrices
\texttt{{[}...,\ :,\ :{]}}.

\subparagraph{Args: }\label{args-28}

\begin{itemize}
\tightlist
\item
  \texttt{input}: A \texttt{Tensor}. Must be one of the following types:
  \texttt{float32}, \texttt{float64}. Shape is
  \texttt{{[}...,\ M,\ M{]}}.
\item
  \texttt{name}: A name for the operation (optional).
\end{itemize}

\subparagraph{Returns: }\label{returns-28}

A \texttt{Tensor}. Has the same type as \texttt{input}. Shape is
\texttt{{[}...{]}}.

\begin{center}\rule{0.5\linewidth}{\linethickness}\end{center}

\subsubsection{\texorpdfstring{\texttt{tf.matrix\_inverse(input,\ name=None)}
}{tf.matrix\_inverse(input, name=None) }}\label{tf.matrixux5finverseinput-namenone}

Calculates the inverse of a square invertible matrix. Checks for
invertibility.

\subparagraph{Args: }\label{args-29}

\begin{itemize}
\tightlist
\item
  \texttt{input}: A \texttt{Tensor}. Must be one of the following types:
  \texttt{float32}, \texttt{float64}. Shape is \texttt{{[}M,\ M{]}}.
\item
  \texttt{name}: A name for the operation (optional).
\end{itemize}

\subparagraph{Returns: }\label{returns-29}

A \texttt{Tensor}. Has the same type as \texttt{input}. Shape is
\texttt{{[}M,\ M{]}} containing the matrix inverse of the input.

\begin{center}\rule{0.5\linewidth}{\linethickness}\end{center}

\subsubsection{\texorpdfstring{\texttt{tf.batch\_matrix\_inverse(input,\ name=None)}
}{tf.batch\_matrix\_inverse(input, name=None) }}\label{tf.batchux5fmatrixux5finverseinput-namenone}

Calculates the inverse of square invertible matrices. Checks for
invertibility.

The input is a tensor of shape \texttt{{[}...,\ M,\ M{]}} whose
inner-most 2 dimensions form square matrices. The output is a tensor of
the same shape as the input containing the inverse for all input
submatrices \texttt{{[}...,\ :,\ :{]}}.

\subparagraph{Args: }\label{args-30}

\begin{itemize}
\tightlist
\item
  \texttt{input}: A \texttt{Tensor}. Must be one of the following types:
  \texttt{float32}, \texttt{float64}. Shape is
  \texttt{{[}...,\ M,\ M{]}}.
\item
  \texttt{name}: A name for the operation (optional).
\end{itemize}

\subparagraph{Returns: }\label{returns-30}

A \texttt{Tensor}. Has the same type as \texttt{input}. Shape is
\texttt{{[}...,\ M,\ M{]}}.

\begin{center}\rule{0.5\linewidth}{\linethickness}\end{center}

\subsubsection{\texorpdfstring{\texttt{tf.cholesky(input,\ name=None)}
}{tf.cholesky(input, name=None) }}\label{tf.choleskyinput-namenone}

Calculates the Cholesky decomposition of a square matrix.

The input has to be symmetric and positive definite. Only the
lower-triangular part of the input will be used for this operation. The
upper-triangular part will not be read.

The result is the lower-triangular matrix of the Cholesky decomposition
of the input.

\subparagraph{Args: }\label{args-31}

\begin{itemize}
\tightlist
\item
  \texttt{input}: A \texttt{Tensor}. Must be one of the following types:
  \texttt{float64}, \texttt{float32}. Shape is \texttt{{[}M,\ M{]}}.
\item
  \texttt{name}: A name for the operation (optional).
\end{itemize}

\subparagraph{Returns: }\label{returns-31}

A \texttt{Tensor}. Has the same type as \texttt{input}. Shape is
\texttt{{[}M,\ M{]}}.

\begin{center}\rule{0.5\linewidth}{\linethickness}\end{center}

\subsubsection{\texorpdfstring{\texttt{tf.batch\_cholesky(input,\ name=None)}
}{tf.batch\_cholesky(input, name=None) }}\label{tf.batchux5fcholeskyinput-namenone}

Calculates the Cholesky decomposition of a batch of square matrices.

The input is a tensor of shape \texttt{{[}...,\ M,\ M{]}} whose
inner-most 2 dimensions form square matrices, with the same constraints
as the single matrix Cholesky decomposition above. The output is a
tensor of the same shape as the input containing the Cholesky
decompositions for all input submatrices \texttt{{[}...,\ :,\ :{]}}.

\subparagraph{Args: }\label{args-32}

\begin{itemize}
\tightlist
\item
  \texttt{input}: A \texttt{Tensor}. Must be one of the following types:
  \texttt{float64}, \texttt{float32}. Shape is
  \texttt{{[}...,\ M,\ M{]}}.
\item
  \texttt{name}: A name for the operation (optional).
\end{itemize}

\subparagraph{Returns: }\label{returns-32}

A \texttt{Tensor}. Has the same type as \texttt{input}. Shape is
\texttt{{[}...,\ M,\ M{]}}.

\subsection{Complex Number Functions }\label{complex-number-functions}

TensorFlow provides several operations that you can use to add complex
number functions to your graph.

\begin{center}\rule{0.5\linewidth}{\linethickness}\end{center}

\subsubsection{\texorpdfstring{\texttt{tf.complex(real,\ imag,\ name=None)}
}{tf.complex(real, imag, name=None) }}\label{tf.complexreal-imag-namenone}

Converts two real numbers to a complex number.

Given a tensor \texttt{real} representing the real part of a complex
number, and a tensor \texttt{imag} representing the imaginary part of a
complex number, this operation computes complex numbers elementwise of
the form \textbackslash{}(a + bj\textbackslash{}), where \emph{a}
represents the \texttt{real} part and \emph{b} represents the
\texttt{imag} part.

The input tensors \texttt{real} and \texttt{imag} must be the same
shape.

For example:

\begin{verbatim}
# tensor 'real' is [2.25, 3.25]
# tensor `imag` is [4.75, 5.75]
tf.complex(real, imag) ==> [[2.25 + 4.74j], [3.25 + 5.75j]]
\end{verbatim}

\subparagraph{Args: }\label{args-33}

\begin{itemize}
\tightlist
\item
  \texttt{real}: A \texttt{Tensor} of type \texttt{float}.
\item
  \texttt{imag}: A \texttt{Tensor} of type \texttt{float}.
\item
  \texttt{name}: A name for the operation (optional).
\end{itemize}

\subparagraph{Returns: }\label{returns-33}

A \texttt{Tensor} of type \texttt{complex64}.

\begin{center}\rule{0.5\linewidth}{\linethickness}\end{center}

\subsubsection{\texorpdfstring{\texttt{tf.complex\_abs(x,\ name=None)}
}{tf.complex\_abs(x, name=None) }}\label{tf.complexux5fabsx-namenone}

Computes the complex absolute value of a tensor.

Given a tensor \texttt{x} of complex numbers, this operation returns a
tensor of type \texttt{float} that is the absolute value of each element
in \texttt{x}. All elements in \texttt{x} must be complex numbers of the
form \textbackslash{}(a + bj\textbackslash{}). The absolute value is
computed as \textbackslash{}( \sqrt{a^2 + b^2}\textbackslash{}).

For example:

\begin{verbatim}
# tensor 'x' is [[-2.25 + 4.75j], [-3.25 + 5.75j]]
tf.complex_abs(x) ==> [5.25594902, 6.60492229]
\end{verbatim}

\subparagraph{Args: }\label{args-34}

\begin{itemize}
\tightlist
\item
  \texttt{x}: A \texttt{Tensor} of type \texttt{complex64}.
\item
  \texttt{name}: A name for the operation (optional).
\end{itemize}

\subparagraph{Returns: }\label{returns-34}

A \texttt{Tensor} of type \texttt{float32}.

\begin{center}\rule{0.5\linewidth}{\linethickness}\end{center}

\subsubsection{\texorpdfstring{\texttt{tf.conj(in\_,\ name=None)}
}{tf.conj(in\_, name=None) }}\label{tf.conjinux5f-namenone}

Returns the complex conjugate of a complex number.

Given a tensor \texttt{in} of complex numbers, this operation returns a
tensor of complex numbers that are the complex conjugate of each element
in \texttt{in}. The complex numbers in \texttt{in} must be of the form
\textbackslash{}(a + bj\textbackslash{}), where \emph{a} is the real
part and \emph{b} is the imaginary part.

The complex conjugate returned by this operation is of the form
\textbackslash{}(a - bj\textbackslash{}).

For example:

\begin{verbatim}
# tensor 'in' is [-2.25 + 4.75j, 3.25 + 5.75j]
tf.conj(in) ==> [-2.25 - 4.75j, 3.25 - 5.75j]
\end{verbatim}

\subparagraph{Args: }\label{args-35}

\begin{itemize}
\tightlist
\item
  \texttt{in\_}: A \texttt{Tensor} of type \texttt{complex64}.
\item
  \texttt{name}: A name for the operation (optional).
\end{itemize}

\subparagraph{Returns: }\label{returns-35}

A \texttt{Tensor} of type \texttt{complex64}.

\begin{center}\rule{0.5\linewidth}{\linethickness}\end{center}

\subsubsection{\texorpdfstring{\texttt{tf.imag(in\_,\ name=None)}
}{tf.imag(in\_, name=None) }}\label{tf.imaginux5f-namenone}

Returns the imaginary part of a complex number.

Given a tensor \texttt{in} of complex numbers, this operation returns a
tensor of type \texttt{float} that is the imaginary part of each element
in \texttt{in}. All elements in \texttt{in} must be complex numbers of
the form \textbackslash{}(a + bj\textbackslash{}), where \emph{a} is the
real part and \emph{b} is the imaginary part returned by this operation.

For example:

\begin{verbatim}
# tensor 'in' is [-2.25 + 4.75j, 3.25 + 5.75j]
tf.imag(in) ==> [4.75, 5.75]
\end{verbatim}

\subparagraph{Args: }\label{args-36}

\begin{itemize}
\tightlist
\item
  \texttt{in\_}: A \texttt{Tensor} of type \texttt{complex64}.
\item
  \texttt{name}: A name for the operation (optional).
\end{itemize}

\subparagraph{Returns: }\label{returns-36}

A \texttt{Tensor} of type \texttt{float32}.

\begin{center}\rule{0.5\linewidth}{\linethickness}\end{center}

\subsubsection{\texorpdfstring{\texttt{tf.real(in\_,\ name=None)}
}{tf.real(in\_, name=None) }}\label{tf.realinux5f-namenone}

Returns the real part of a complex number.

Given a tensor \texttt{in} of complex numbers, this operation returns a
tensor of type \texttt{float} that is the real part of each element in
\texttt{in}. All elements in \texttt{in} must be complex numbers of the
form \textbackslash{}(a + bj\textbackslash{}), where \emph{a} is the
real part returned by this operation and \emph{b} is the imaginary part.

For example:

\begin{verbatim}
# tensor 'in' is [-2.25 + 4.75j, 3.25 + 5.75j]
tf.real(in) ==> [-2.25, 3.25]
\end{verbatim}

\subparagraph{Args: }\label{args-37}

\begin{itemize}
\tightlist
\item
  \texttt{in\_}: A \texttt{Tensor} of type \texttt{complex64}.
\item
  \texttt{name}: A name for the operation (optional).
\end{itemize}

\subparagraph{Returns: }\label{returns-37}

A \texttt{Tensor} of type \texttt{float32}.

\subsection{Reduction }\label{reduction}

TensorFlow provides several operations that you can use to perform
common math computations that reduce various dimensions of a tensor.

\begin{center}\rule{0.5\linewidth}{\linethickness}\end{center}

\subsubsection{\texorpdfstring{\texttt{tf.reduce\_sum(input\_tensor,\ reduction\_indices=None,\ keep\_dims=False,\ name=None)}
}{tf.reduce\_sum(input\_tensor, reduction\_indices=None, keep\_dims=False, name=None) }}\label{tf.reduceux5fsuminputux5ftensor-reductionux5findicesnone-keepux5fdimsfalse-namenone}

Computes the sum of elements across dimensions of a tensor.

Reduces \texttt{input\_tensor} along the dimensions given in
\texttt{reduction\_indices}. Unless \texttt{keep\_dims} is true, the
rank of the tensor is reduced by 1 for each entry in
\texttt{reduction\_indices}. If \texttt{keep\_dims} is true, the reduced
dimensions are retained with length 1.

If \texttt{reduction\_indices} has no entries, all dimensions are
reduced, and a tensor with a single element is returned.

For example:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# 'x' is [[1, 1, 1]]}
\CommentTok{#         [1, 1, 1]]}
\NormalTok{tf.reduce_sum(x) }\OperatorTok{==>} \DecValTok{6}
\NormalTok{tf.reduce_sum(x, }\DecValTok{0}\NormalTok{) }\OperatorTok{==>} \NormalTok{[}\DecValTok{2}\NormalTok{, }\DecValTok{2}\NormalTok{, }\DecValTok{2}\NormalTok{]}
\NormalTok{tf.reduce_sum(x, }\DecValTok{1}\NormalTok{) }\OperatorTok{==>} \NormalTok{[}\DecValTok{3}\NormalTok{, }\DecValTok{3}\NormalTok{]}
\NormalTok{tf.reduce_sum(x, }\DecValTok{1}\NormalTok{, keep_dims}\OperatorTok{=}\VariableTok{True}\NormalTok{) }\OperatorTok{==>} \NormalTok{[[}\DecValTok{3}\NormalTok{], [}\DecValTok{3}\NormalTok{]]}
\NormalTok{tf.reduce_sum(x, [}\DecValTok{0}\NormalTok{, }\DecValTok{1}\NormalTok{]) }\OperatorTok{==>} \DecValTok{6}
\end{Highlighting}
\end{Shaded}

\subparagraph{Args: }\label{args-38}

\begin{itemize}
\tightlist
\item
  \texttt{input\_tensor}: The tensor to reduce. Should have numeric
  type.
\item
  \texttt{reduction\_indices}: The dimensions to reduce. If
  \texttt{None} (the defaut), reduces all dimensions.
\item
  \texttt{keep\_dims}: If true, retains reduced dimensions with length
  1.
\item
  \texttt{name}: A name for the operation (optional).
\end{itemize}

\subparagraph{Returns: }\label{returns-38}

The reduced tensor.

\begin{center}\rule{0.5\linewidth}{\linethickness}\end{center}

\subsubsection{\texorpdfstring{\texttt{tf.reduce\_prod(input\_tensor,\ reduction\_indices=None,\ keep\_dims=False,\ name=None)}
}{tf.reduce\_prod(input\_tensor, reduction\_indices=None, keep\_dims=False, name=None) }}\label{tf.reduceux5fprodinputux5ftensor-reductionux5findicesnone-keepux5fdimsfalse-namenone}

Computes the product of elements across dimensions of a tensor.

Reduces \texttt{input\_tensor} along the dimensions given in
\texttt{reduction\_indices}. Unless \texttt{keep\_dims} is true, the
rank of the tensor is reduced by 1 for each entry in
\texttt{reduction\_indices}. If \texttt{keep\_dims} is true, the reduced
dimensions are retained with length 1.

If \texttt{reduction\_indices} has no entries, all dimensions are
reduced, and a tensor with a single element is returned.

\subparagraph{Args: }\label{args-39}

\begin{itemize}
\tightlist
\item
  \texttt{input\_tensor}: The tensor to reduce. Should have numeric
  type.
\item
  \texttt{reduction\_indices}: The dimensions to reduce. If
  \texttt{None} (the defaut), reduces all dimensions.
\item
  \texttt{keep\_dims}: If true, retains reduced dimensions with length
  1.
\item
  \texttt{name}: A name for the operation (optional).
\end{itemize}

\subparagraph{Returns: }\label{returns-39}

The reduced tensor.

\begin{center}\rule{0.5\linewidth}{\linethickness}\end{center}

\subsubsection{\texorpdfstring{\texttt{tf.reduce\_min(input\_tensor,\ reduction\_indices=None,\ keep\_dims=False,\ name=None)}
}{tf.reduce\_min(input\_tensor, reduction\_indices=None, keep\_dims=False, name=None) }}\label{tf.reduceux5fmininputux5ftensor-reductionux5findicesnone-keepux5fdimsfalse-namenone}

Computes the minimum of elements across dimensions of a tensor.

Reduces \texttt{input\_tensor} along the dimensions given in
\texttt{reduction\_indices}. Unless \texttt{keep\_dims} is true, the
rank of the tensor is reduced by 1 for each entry in
\texttt{reduction\_indices}. If \texttt{keep\_dims} is true, the reduced
dimensions are retained with length 1.

If \texttt{reduction\_indices} has no entries, all dimensions are
reduced, and a tensor with a single element is returned.

\subparagraph{Args: }\label{args-40}

\begin{itemize}
\tightlist
\item
  \texttt{input\_tensor}: The tensor to reduce. Should have numeric
  type.
\item
  \texttt{reduction\_indices}: The dimensions to reduce. If
  \texttt{None} (the defaut), reduces all dimensions.
\item
  \texttt{keep\_dims}: If true, retains reduced dimensions with length
  1.
\item
  \texttt{name}: A name for the operation (optional).
\end{itemize}

\subparagraph{Returns: }\label{returns-40}

The reduced tensor.

\begin{center}\rule{0.5\linewidth}{\linethickness}\end{center}

\subsubsection{\texorpdfstring{\texttt{tf.reduce\_max(input\_tensor,\ reduction\_indices=None,\ keep\_dims=False,\ name=None)}
}{tf.reduce\_max(input\_tensor, reduction\_indices=None, keep\_dims=False, name=None) }}\label{tf.reduceux5fmaxinputux5ftensor-reductionux5findicesnone-keepux5fdimsfalse-namenone}

Computes the maximum of elements across dimensions of a tensor.

Reduces \texttt{input\_tensor} along the dimensions given in
\texttt{reduction\_indices}. Unless \texttt{keep\_dims} is true, the
rank of the tensor is reduced by 1 for each entry in
\texttt{reduction\_indices}. If \texttt{keep\_dims} is true, the reduced
dimensions are retained with length 1.

If \texttt{reduction\_indices} has no entries, all dimensions are
reduced, and a tensor with a single element is returned.

\subparagraph{Args: }\label{args-41}

\begin{itemize}
\tightlist
\item
  \texttt{input\_tensor}: The tensor to reduce. Should have numeric
  type.
\item
  \texttt{reduction\_indices}: The dimensions to reduce. If
  \texttt{None} (the defaut), reduces all dimensions.
\item
  \texttt{keep\_dims}: If true, retains reduced dimensions with length
  1.
\item
  \texttt{name}: A name for the operation (optional).
\end{itemize}

\subparagraph{Returns: }\label{returns-41}

The reduced tensor.

\begin{center}\rule{0.5\linewidth}{\linethickness}\end{center}

\subsubsection{\texorpdfstring{\texttt{tf.reduce\_mean(input\_tensor,\ reduction\_indices=None,\ keep\_dims=False,\ name=None)}
}{tf.reduce\_mean(input\_tensor, reduction\_indices=None, keep\_dims=False, name=None) }}\label{tf.reduceux5fmeaninputux5ftensor-reductionux5findicesnone-keepux5fdimsfalse-namenone}

Computes the mean of elements across dimensions of a tensor.

Reduces \texttt{input\_tensor} along the dimensions given in
\texttt{reduction\_indices}. Unless \texttt{keep\_dims} is true, the
rank of the tensor is reduced by 1 for each entry in
\texttt{reduction\_indices}. If \texttt{keep\_dims} is true, the reduced
dimensions are retained with length 1.

If \texttt{reduction\_indices} has no entries, all dimensions are
reduced, and a tensor with a single element is returned.

For example:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# 'x' is [[1., 1. ]]}
\CommentTok{#         [2., 2.]]}
\NormalTok{tf.reduce_mean(x) }\OperatorTok{==>} \FloatTok{1.5}
\NormalTok{tf.reduce_mean(x, }\DecValTok{0}\NormalTok{) }\OperatorTok{==>} \NormalTok{[}\FloatTok{1.5}\NormalTok{, }\FloatTok{1.5}\NormalTok{]}
\NormalTok{tf.reduce_mean(x, }\DecValTok{1}\NormalTok{) }\OperatorTok{==>} \NormalTok{[}\DecValTok{1}\NormalTok{.,  }\DecValTok{2}\NormalTok{.]}
\end{Highlighting}
\end{Shaded}

\subparagraph{Args: }\label{args-42}

\begin{itemize}
\tightlist
\item
  \texttt{input\_tensor}: The tensor to reduce. Should have numeric
  type.
\item
  \texttt{reduction\_indices}: The dimensions to reduce. If
  \texttt{None} (the defaut), reduces all dimensions.
\item
  \texttt{keep\_dims}: If true, retains reduced dimensions with length
  1.
\item
  \texttt{name}: A name for the operation (optional).
\end{itemize}

\subparagraph{Returns: }\label{returns-42}

The reduced tensor.

\begin{center}\rule{0.5\linewidth}{\linethickness}\end{center}

\subsubsection{\texorpdfstring{\texttt{tf.reduce\_all(input\_tensor,\ reduction\_indices=None,\ keep\_dims=False,\ name=None)}
}{tf.reduce\_all(input\_tensor, reduction\_indices=None, keep\_dims=False, name=None) }}\label{tf.reduceux5fallinputux5ftensor-reductionux5findicesnone-keepux5fdimsfalse-namenone}

Computes the ``logical and'' of elements across dimensions of a tensor.

Reduces \texttt{input\_tensor} along the dimensions given in
\texttt{reduction\_indices}. Unless \texttt{keep\_dims} is true, the
rank of the tensor is reduced by 1 for each entry in
\texttt{reduction\_indices}. If \texttt{keep\_dims} is true, the reduced
dimensions are retained with length 1.

If \texttt{reduction\_indices} has no entries, all dimensions are
reduced, and a tensor with a single element is returned.

For example:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# 'x' is [[True,  True]]}
\CommentTok{#         [False, False]]}
\NormalTok{tf.reduce_all(x) }\OperatorTok{==>} \VariableTok{False}
\NormalTok{tf.reduce_all(x, }\DecValTok{0}\NormalTok{) }\OperatorTok{==>} \NormalTok{[}\VariableTok{False}\NormalTok{, }\VariableTok{False}\NormalTok{]}
\NormalTok{tf.reduce_all(x, }\DecValTok{1}\NormalTok{) }\OperatorTok{==>} \NormalTok{[}\VariableTok{True}\NormalTok{, }\VariableTok{False}\NormalTok{]}
\end{Highlighting}
\end{Shaded}

\subparagraph{Args: }\label{args-43}

\begin{itemize}
\tightlist
\item
  \texttt{input\_tensor}: The boolean tensor to reduce.
\item
  \texttt{reduction\_indices}: The dimensions to reduce. If
  \texttt{None} (the defaut), reduces all dimensions.
\item
  \texttt{keep\_dims}: If true, retains reduced dimensions with length
  1.
\item
  \texttt{name}: A name for the operation (optional).
\end{itemize}

\subparagraph{Returns: }\label{returns-43}

The reduced tensor.

\begin{center}\rule{0.5\linewidth}{\linethickness}\end{center}

\subsubsection{\texorpdfstring{\texttt{tf.reduce\_any(input\_tensor,\ reduction\_indices=None,\ keep\_dims=False,\ name=None)}
}{tf.reduce\_any(input\_tensor, reduction\_indices=None, keep\_dims=False, name=None) }}\label{tf.reduceux5fanyinputux5ftensor-reductionux5findicesnone-keepux5fdimsfalse-namenone}

Computes the ``logical or'' of elements across dimensions of a tensor.

Reduces \texttt{input\_tensor} along the dimensions given in
\texttt{reduction\_indices}. Unless \texttt{keep\_dims} is true, the
rank of the tensor is reduced by 1 for each entry in
\texttt{reduction\_indices}. If \texttt{keep\_dims} is true, the reduced
dimensions are retained with length 1.

If \texttt{reduction\_indices} has no entries, all dimensions are
reduced, and a tensor with a single element is returned.

For example:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# 'x' is [[True,  True]]}
\CommentTok{#         [False, False]]}
\NormalTok{tf.reduce_any(x) }\OperatorTok{==>} \VariableTok{True}
\NormalTok{tf.reduce_any(x, }\DecValTok{0}\NormalTok{) }\OperatorTok{==>} \NormalTok{[}\VariableTok{True}\NormalTok{, }\VariableTok{True}\NormalTok{]}
\NormalTok{tf.reduce_any(x, }\DecValTok{1}\NormalTok{) }\OperatorTok{==>} \NormalTok{[}\VariableTok{True}\NormalTok{, }\VariableTok{False}\NormalTok{]}
\end{Highlighting}
\end{Shaded}

\subparagraph{Args: }\label{args-44}

\begin{itemize}
\tightlist
\item
  \texttt{input\_tensor}: The boolean tensor to reduce.
\item
  \texttt{reduction\_indices}: The dimensions to reduce. If
  \texttt{None} (the defaut), reduces all dimensions.
\item
  \texttt{keep\_dims}: If true, retains reduced dimensions with length
  1.
\item
  \texttt{name}: A name for the operation (optional).
\end{itemize}

\subparagraph{Returns: }\label{returns-44}

The reduced tensor.

\begin{center}\rule{0.5\linewidth}{\linethickness}\end{center}

\subsubsection{\texorpdfstring{\texttt{tf.accumulate\_n(inputs,\ shape=None,\ tensor\_dtype=None,\ name=None)}
}{tf.accumulate\_n(inputs, shape=None, tensor\_dtype=None, name=None) }}\label{tf.accumulateux5fninputs-shapenone-tensorux5fdtypenone-namenone}

Returns the element-wise sum of a list of tensors.

Optionally, pass \texttt{shape} and \texttt{tensor\_dtype} for shape and
type checking, otherwise, these are inferred.

For example:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# tensor 'a' is [[1, 2], [3, 4]}
\CommentTok{# tensor `b` is [[5, 0], [0, 6]]}
\NormalTok{tf.accumulate_n([a, b, a]) }\OperatorTok{==>} \NormalTok{[[}\DecValTok{7}\NormalTok{, }\DecValTok{4}\NormalTok{], [}\DecValTok{6}\NormalTok{, }\DecValTok{14}\NormalTok{]]}

\CommentTok{# Explicitly pass shape and type}
\NormalTok{tf.accumulate_n([a, b, a], shape}\OperatorTok{=}\NormalTok{[}\DecValTok{2}\NormalTok{, }\DecValTok{2}\NormalTok{], tensor_dtype}\OperatorTok{=}\NormalTok{tf.int32)}
  \OperatorTok{==>} \NormalTok{[[}\DecValTok{7}\NormalTok{, }\DecValTok{4}\NormalTok{], [}\DecValTok{6}\NormalTok{, }\DecValTok{14}\NormalTok{]]}
\end{Highlighting}
\end{Shaded}

\subparagraph{Args: }\label{args-45}

\begin{itemize}
\tightlist
\item
  \texttt{inputs}: A list of \texttt{Tensor} objects, each with same
  shape and type.
\item
  \texttt{shape}: Shape of elements of \texttt{inputs}.
\item
  \texttt{tensor\_dtype}: The type of \texttt{inputs}.
\item
  \texttt{name}: A name for the operation (optional).
\end{itemize}

\subparagraph{Returns: }\label{returns-45}

A \texttt{Tensor} of same shape and type as the elements of
\texttt{inputs}.

\subparagraph{Raises: }\label{raises}

\begin{itemize}
\tightlist
\item
  \texttt{ValueError}: If \texttt{inputs} don't all have same shape and
  dtype or the shape cannot be inferred.
\end{itemize}

\subsection{Segmentation }\label{segmentation}

TensorFlow provides several operations that you can use to perform
common math computations on tensor segments. Here a segmentation is a
partitioning of a tensor along the first dimension, i.e.~it defines a
mapping from the first dimension onto \texttt{segment\_ids}. The
\texttt{segment\_ids} tensor should be the size of the first dimension,
\texttt{d0}, with consecutive IDs in the range \texttt{0} to \texttt{k},
where \texttt{k\textless{}d0}. In particular, a segmentation of a matrix
tensor is a mapping of rows to segments.

For example:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{c }\OperatorTok{=} \NormalTok{tf.constant([[}\DecValTok{1}\NormalTok{,}\DecValTok{2}\NormalTok{,}\DecValTok{3}\NormalTok{,}\DecValTok{4}\NormalTok{], [}\OperatorTok{-}\DecValTok{1}\NormalTok{,}\OperatorTok{-}\DecValTok{2}\NormalTok{,}\OperatorTok{-}\DecValTok{3}\NormalTok{,}\OperatorTok{-}\DecValTok{4}\NormalTok{], [}\DecValTok{5}\NormalTok{,}\DecValTok{6}\NormalTok{,}\DecValTok{7}\NormalTok{,}\DecValTok{8}\NormalTok{]])}
\NormalTok{tf.segment_sum(c, tf.constant([}\DecValTok{0}\NormalTok{, }\DecValTok{0}\NormalTok{, }\DecValTok{1}\NormalTok{]))}
  \OperatorTok{==>}  \NormalTok{[[}\DecValTok{0} \DecValTok{0} \DecValTok{0} \DecValTok{0}\NormalTok{]}
        \NormalTok{[}\DecValTok{5} \DecValTok{6} \DecValTok{7} \DecValTok{8}\NormalTok{]]}
\end{Highlighting}
\end{Shaded}

\begin{center}\rule{0.5\linewidth}{\linethickness}\end{center}

\subsubsection{\texorpdfstring{\texttt{tf.segment\_sum(data,\ segment\_ids,\ name=None)}
}{tf.segment\_sum(data, segment\_ids, name=None) }}\label{tf.segmentux5fsumdata-segmentux5fids-namenone}

Computes the sum along segments of a tensor.

Read \href{../../api_docs/python/math_ops.md\#segmentation}{the section
on Segmentation} for an explanation of segments.

Computes a tensor such that \textbackslash{}(output\_i = \sum\_j
data\_j\textbackslash{}) where sum is over \texttt{j} such that
\texttt{segment\_ids{[}j{]}\ ==\ i}.

\subparagraph{Args: }\label{args-46}

\begin{itemize}
\tightlist
\item
  \texttt{data}: A \texttt{Tensor}. Must be one of the following types:
  \texttt{float32}, \texttt{float64}, \texttt{int32}, \texttt{int64},
  \texttt{uint8}, \texttt{int16}, \texttt{int8}.
\item
  \texttt{segment\_ids}: A \texttt{Tensor}. Must be one of the following
  types: \texttt{int32}, \texttt{int64}. A 1-D tensor whose rank is
  equal to the rank of \texttt{data}'s first dimension. Values should be
  sorted and can be repeated.
\item
  \texttt{name}: A name for the operation (optional).
\end{itemize}

\subparagraph{Returns: }\label{returns-46}

A \texttt{Tensor}. Has the same type as \texttt{data}. Has same shape as
data, except for dimension\_0 which has size \texttt{k}, the number of
segments.

\begin{center}\rule{0.5\linewidth}{\linethickness}\end{center}

\subsubsection{\texorpdfstring{\texttt{tf.segment\_prod(data,\ segment\_ids,\ name=None)}
}{tf.segment\_prod(data, segment\_ids, name=None) }}\label{tf.segmentux5fproddata-segmentux5fids-namenone}

Computes the product along segments of a tensor.

Read \href{../../api_docs/python/math_ops.md\#segmentation}{the section
on Segmentation} for an explanation of segments.

Computes a tensor such that \textbackslash{}(output\_i = \prod\_j
data\_j\textbackslash{}) where the product is over \texttt{j} such that
\texttt{segment\_ids{[}j{]}\ ==\ i}.

\subparagraph{Args: }\label{args-47}

\begin{itemize}
\tightlist
\item
  \texttt{data}: A \texttt{Tensor}. Must be one of the following types:
  \texttt{float32}, \texttt{float64}, \texttt{int32}, \texttt{int64},
  \texttt{uint8}, \texttt{int16}, \texttt{int8}.
\item
  \texttt{segment\_ids}: A \texttt{Tensor}. Must be one of the following
  types: \texttt{int32}, \texttt{int64}. A 1-D tensor whose rank is
  equal to the rank of \texttt{data}'s first dimension. Values should be
  sorted and can be repeated.
\item
  \texttt{name}: A name for the operation (optional).
\end{itemize}

\subparagraph{Returns: }\label{returns-47}

A \texttt{Tensor}. Has the same type as \texttt{data}. Has same shape as
data, except for dimension\_0 which has size \texttt{k}, the number of
segments.

\begin{center}\rule{0.5\linewidth}{\linethickness}\end{center}

\subsubsection{\texorpdfstring{\texttt{tf.segment\_min(data,\ segment\_ids,\ name=None)}
}{tf.segment\_min(data, segment\_ids, name=None) }}\label{tf.segmentux5fmindata-segmentux5fids-namenone}

Computes the minimum along segments of a tensor.

Read \href{../../api_docs/python/math_ops.md\#segmentation}{the section
on Segmentation} for an explanation of segments.

Computes a tensor such that \textbackslash{}(output\_i =
\min\_j(data\_j)\textbackslash{}) where \texttt{min} is over \texttt{j}
such that \texttt{segment\_ids{[}j{]}\ ==\ i}.

\subparagraph{Args: }\label{args-48}

\begin{itemize}
\tightlist
\item
  \texttt{data}: A \texttt{Tensor}. Must be one of the following types:
  \texttt{float32}, \texttt{float64}, \texttt{int32}, \texttt{int64},
  \texttt{uint8}, \texttt{int16}, \texttt{int8}.
\item
  \texttt{segment\_ids}: A \texttt{Tensor}. Must be one of the following
  types: \texttt{int32}, \texttt{int64}. A 1-D tensor whose rank is
  equal to the rank of \texttt{data}'s first dimension. Values should be
  sorted and can be repeated.
\item
  \texttt{name}: A name for the operation (optional).
\end{itemize}

\subparagraph{Returns: }\label{returns-48}

A \texttt{Tensor}. Has the same type as \texttt{data}. Has same shape as
data, except for dimension\_0 which has size \texttt{k}, the number of
segments.

\begin{center}\rule{0.5\linewidth}{\linethickness}\end{center}

\subsubsection{\texorpdfstring{\texttt{tf.segment\_max(data,\ segment\_ids,\ name=None)}
}{tf.segment\_max(data, segment\_ids, name=None) }}\label{tf.segmentux5fmaxdata-segmentux5fids-namenone}

Computes the maximum along segments of a tensor.

Read \href{../../api_docs/python/math_ops.md\#segmentation}{the section
on Segmentation} for an explanation of segments.

Computes a tensor such that \textbackslash{}(output\_i =
\max\_j(data\_j)\textbackslash{}) where \texttt{max} is over \texttt{j}
such that \texttt{segment\_ids{[}j{]}\ ==\ i}.

\subparagraph{Args: }\label{args-49}

\begin{itemize}
\tightlist
\item
  \texttt{data}: A \texttt{Tensor}. Must be one of the following types:
  \texttt{float32}, \texttt{float64}, \texttt{int32}, \texttt{int64},
  \texttt{uint8}, \texttt{int16}, \texttt{int8}.
\item
  \texttt{segment\_ids}: A \texttt{Tensor}. Must be one of the following
  types: \texttt{int32}, \texttt{int64}. A 1-D tensor whose rank is
  equal to the rank of \texttt{data}'s first dimension. Values should be
  sorted and can be repeated.
\item
  \texttt{name}: A name for the operation (optional).
\end{itemize}

\subparagraph{Returns: }\label{returns-49}

A \texttt{Tensor}. Has the same type as \texttt{data}. Has same shape as
data, except for dimension\_0 which has size \texttt{k}, the number of
segments.

\begin{center}\rule{0.5\linewidth}{\linethickness}\end{center}

\subsubsection{\texorpdfstring{\texttt{tf.segment\_mean(data,\ segment\_ids,\ name=None)}
}{tf.segment\_mean(data, segment\_ids, name=None) }}\label{tf.segmentux5fmeandata-segmentux5fids-namenone}

Computes the mean along segments of a tensor.

Read \href{../../api_docs/python/math_ops.md\#segmentation}{the section
on Segmentation} for an explanation of segments.

Computes a tensor such that \textbackslash{}(output\_i =
\frac{\sum_j data_j}{N}\textbackslash{}) where \texttt{mean} is over
\texttt{j} such that \texttt{segment\_ids{[}j{]}\ ==\ i} and \texttt{N}
is the total number of values summed.

\subparagraph{Args: }\label{args-50}

\begin{itemize}
\tightlist
\item
  \texttt{data}: A \texttt{Tensor}. Must be one of the following types:
  \texttt{float32}, \texttt{float64}, \texttt{int32}, \texttt{int64},
  \texttt{uint8}, \texttt{int16}, \texttt{int8}.
\item
  \texttt{segment\_ids}: A \texttt{Tensor}. Must be one of the following
  types: \texttt{int32}, \texttt{int64}. A 1-D tensor whose rank is
  equal to the rank of \texttt{data}'s first dimension. Values should be
  sorted and can be repeated.
\item
  \texttt{name}: A name for the operation (optional).
\end{itemize}

\subparagraph{Returns: }\label{returns-50}

A \texttt{Tensor}. Has the same type as \texttt{data}. Has same shape as
data, except for dimension\_0 which has size \texttt{k}, the number of
segments.

\begin{center}\rule{0.5\linewidth}{\linethickness}\end{center}

\subsubsection{\texorpdfstring{\texttt{tf.unsorted\_segment\_sum(data,\ segment\_ids,\ num\_segments,\ name=None)}
}{tf.unsorted\_segment\_sum(data, segment\_ids, num\_segments, name=None) }}\label{tf.unsortedux5fsegmentux5fsumdata-segmentux5fids-numux5fsegments-namenone}

Computes the sum along segments of a tensor.

Read \href{../../api_docs/python/math_ops.md\#segmentation}{the section
on Segmentation} for an explanation of segments.

Computes a tensor such that \textbackslash{}(output\_i = \sum\_j
data\_j\textbackslash{}) where sum is over \texttt{j} such that
\texttt{segment\_ids{[}j{]}\ ==\ i}. Unlike \texttt{SegmentSum},
\texttt{segment\_ids} need not be sorted and need not cover all values
in the full range of valid values.

If the sum is empty for a given segment ID \texttt{i},
\texttt{output{[}i{]}\ =\ 0}.

\texttt{num\_segments} should equal the number of distinct segment IDs.

\subparagraph{Args: }\label{args-51}

\begin{itemize}
\tightlist
\item
  \texttt{data}: A \texttt{Tensor}. Must be one of the following types:
  \texttt{float32}, \texttt{float64}, \texttt{int32}, \texttt{int64},
  \texttt{uint8}, \texttt{int16}, \texttt{int8}.
\item
  \texttt{segment\_ids}: A \texttt{Tensor}. Must be one of the following
  types: \texttt{int32}, \texttt{int64}. A 1-D tensor whose rank is
  equal to the rank of \texttt{data}'s first dimension.
\item
  \texttt{num\_segments}: A \texttt{Tensor} of type \texttt{int32}.
\item
  \texttt{name}: A name for the operation (optional).
\end{itemize}

\subparagraph{Returns: }\label{returns-51}

A \texttt{Tensor}. Has the same type as \texttt{data}. Has same shape as
data, except for dimension\_0 which has size \texttt{num\_segments}.

\begin{center}\rule{0.5\linewidth}{\linethickness}\end{center}

\subsubsection{\texorpdfstring{\texttt{tf.sparse\_segment\_sum(data,\ indices,\ segment\_ids,\ name=None)}
}{tf.sparse\_segment\_sum(data, indices, segment\_ids, name=None) }}\label{tf.sparseux5fsegmentux5fsumdata-indices-segmentux5fids-namenone}

Computes the sum along sparse segments of a tensor.

Read \href{../../api_docs/python/math_ops.md\#segmentation}{the section
on Segmentation} for an explanation of segments.

Like \texttt{SegmentSum}, but \texttt{segment\_ids} can have rank less
than \texttt{data}'s first dimension, selecting a subset of
dimension\_0, specified by \texttt{indices}.

For example:

\begin{verbatim}
c = tf.constant([[1,2,3,4], [-1,-2,-3,-4], [5,6,7,8]])

# Select two rows, one segment.
tf.sparse_segment_sum(c, tf.constant([0, 1]), tf.constant([0, 0]))
  ==> [[0 0 0 0]]

# Select two rows, two segment.
tf.sparse_segment_sum(c, tf.constant([0, 1]), tf.constant([0, 1]))
  ==> [[ 1  2  3  4]
       [-1 -2 -3 -4]]

# Select all rows, two segments.
tf.sparse_segment_sum(c, tf.constant([0, 1, 2]), tf.constant([0, 0, 1]))
  ==> [[0 0 0 0]
       [5 6 7 8]]

# Which is equivalent to:
tf.segment_sum(c, tf.constant([0, 0, 1]))
\end{verbatim}

\subparagraph{Args: }\label{args-52}

\begin{itemize}
\tightlist
\item
  \texttt{data}: A \texttt{Tensor}. Must be one of the following types:
  \texttt{float32}, \texttt{float64}, \texttt{int32}, \texttt{int64},
  \texttt{uint8}, \texttt{int16}, \texttt{int8}.
\item
  \texttt{indices}: A \texttt{Tensor} of type \texttt{int32}. A 1-D
  tensor. Has same rank as \texttt{segment\_ids}.
\item
  \texttt{segment\_ids}: A \texttt{Tensor} of type \texttt{int32}. A 1-D
  tensor. Values should be sorted and can be repeated.
\item
  \texttt{name}: A name for the operation (optional).
\end{itemize}

\subparagraph{Returns: }\label{returns-52}

A \texttt{Tensor}. Has the same type as \texttt{data}. Has same shape as
data, except for dimension\_0 which has size \texttt{k}, the number of
segments.

\begin{center}\rule{0.5\linewidth}{\linethickness}\end{center}

\subsubsection{\texorpdfstring{\texttt{tf.sparse\_segment\_mean(data,\ indices,\ segment\_ids,\ name=None)}
}{tf.sparse\_segment\_mean(data, indices, segment\_ids, name=None) }}\label{tf.sparseux5fsegmentux5fmeandata-indices-segmentux5fids-namenone}

Computes the mean along sparse segments of a tensor.

Read \href{../../api_docs/python/math_ops.md\#segmentation}{the section
on Segmentation} for an explanation of segments.

Like \texttt{SegmentMean}, but \texttt{segment\_ids} can have rank less
than \texttt{data}'s first dimension, selecting a subset of
dimension\_0, specified by \texttt{indices}.

\subparagraph{Args: }\label{args-53}

\begin{itemize}
\tightlist
\item
  \texttt{data}: A \texttt{Tensor}. Must be one of the following types:
  \texttt{float32}, \texttt{float64}.
\item
  \texttt{indices}: A \texttt{Tensor} of type \texttt{int32}. A 1-D
  tensor. Has same rank as \texttt{segment\_ids}.
\item
  \texttt{segment\_ids}: A \texttt{Tensor} of type \texttt{int32}. A 1-D
  tensor. Values should be sorted and can be repeated.
\item
  \texttt{name}: A name for the operation (optional).
\end{itemize}

\subparagraph{Returns: }\label{returns-53}

A \texttt{Tensor}. Has the same type as \texttt{data}. Has same shape as
data, except for dimension\_0 which has size \texttt{k}, the number of
segments.

\subsection{Sequence Comparison and Indexing
}\label{sequence-comparison-and-indexing}

TensorFlow provides several operations that you can use to add sequence
comparison and index extraction to your graph. You can use these
operations to determine sequence differences and determine the indexes
of specific values in a tensor.

\begin{center}\rule{0.5\linewidth}{\linethickness}\end{center}

\subsubsection{\texorpdfstring{\texttt{tf.argmin(input,\ dimension,\ name=None)}
}{tf.argmin(input, dimension, name=None) }}\label{tf.argmininput-dimension-namenone}

Returns the index with the smallest value across dimensions of a tensor.

\subparagraph{Args: }\label{args-54}

\begin{itemize}
\tightlist
\item
  \texttt{input}: A \texttt{Tensor}. Must be one of the following types:
  \texttt{float32}, \texttt{float64}, \texttt{int64}, \texttt{int32},
  \texttt{uint8}, \texttt{int16}, \texttt{int8}, \texttt{complex64},
  \texttt{qint8}, \texttt{quint8}, \texttt{qint32}.
\item
  \texttt{dimension}: A \texttt{Tensor} of type \texttt{int32}. int32, 0
  \textless{}= dimension \textless{} rank(input). Describes which
  dimension of the input Tensor to reduce across. For vectors, use
  dimension = 0.
\item
  \texttt{name}: A name for the operation (optional).
\end{itemize}

\subparagraph{Returns: }\label{returns-54}

A \texttt{Tensor} of type \texttt{int64}.

\begin{center}\rule{0.5\linewidth}{\linethickness}\end{center}

\subsubsection{\texorpdfstring{\texttt{tf.argmax(input,\ dimension,\ name=None)}
}{tf.argmax(input, dimension, name=None) }}\label{tf.argmaxinput-dimension-namenone}

Returns the index with the largest value across dimensions of a tensor.

\subparagraph{Args: }\label{args-55}

\begin{itemize}
\tightlist
\item
  \texttt{input}: A \texttt{Tensor}. Must be one of the following types:
  \texttt{float32}, \texttt{float64}, \texttt{int64}, \texttt{int32},
  \texttt{uint8}, \texttt{int16}, \texttt{int8}, \texttt{complex64},
  \texttt{qint8}, \texttt{quint8}, \texttt{qint32}.
\item
  \texttt{dimension}: A \texttt{Tensor} of type \texttt{int32}. int32, 0
  \textless{}= dimension \textless{} rank(input). Describes which
  dimension of the input Tensor to reduce across. For vectors, use
  dimension = 0.
\item
  \texttt{name}: A name for the operation (optional).
\end{itemize}

\subparagraph{Returns: }\label{returns-55}

A \texttt{Tensor} of type \texttt{int64}.

\begin{center}\rule{0.5\linewidth}{\linethickness}\end{center}

\subsubsection{\texorpdfstring{\texttt{tf.listdiff(x,\ y,\ name=None)}
}{tf.listdiff(x, y, name=None) }}\label{tf.listdiffx-y-namenone}

Computes the difference between two lists of numbers.

Given a list \texttt{x} and a list \texttt{y}, this operation returns a
list \texttt{out} that represents all numbers that are in \texttt{x} but
not in \texttt{y}. The returned list \texttt{out} is sorted in the same
order that the numbers appear in \texttt{x} (duplicates are preserved).
This operation also returns a list \texttt{idx} that represents the
position of each \texttt{out} element in \texttt{x}. In other words:

\texttt{out{[}i{]}\ =\ x{[}idx{[}i{]}{]}\ for\ i\ in\ {[}0,\ 1,\ ...,\ len(out)\ -\ 1{]}}

For example, given this input:

\begin{verbatim}
x = [1, 2, 3, 4, 5, 6]
y = [1, 3, 5]
\end{verbatim}

This operation would return:

\begin{verbatim}
out ==> [2, 4, 6]
idx ==> [1, 3, 5]
\end{verbatim}

\subparagraph{Args: }\label{args-56}

\begin{itemize}
\tightlist
\item
  \texttt{x}: A \texttt{Tensor}. 1-D. Values to keep.
\item
  \texttt{y}: A \texttt{Tensor}. Must have the same type as \texttt{x}.
  1-D. Values to remove.
\item
  \texttt{name}: A name for the operation (optional).
\end{itemize}

\subparagraph{Returns: }\label{returns-56}

A tuple of \texttt{Tensor} objects (out, idx).

\begin{itemize}
\tightlist
\item
  \texttt{out}: A \texttt{Tensor}. Has the same type as \texttt{x}. 1-D.
  Values present in \texttt{x} but not in \texttt{y}.
\item
  \texttt{idx}: A \texttt{Tensor} of type \texttt{int32}. 1-D. Positions
  of \texttt{x} values preserved in \texttt{out}.
\end{itemize}

\begin{center}\rule{0.5\linewidth}{\linethickness}\end{center}

\subsubsection{\texorpdfstring{\texttt{tf.where(input,\ name=None)}
}{tf.where(input, name=None) }}\label{tf.whereinput-namenone}

Returns locations of true values in a boolean tensor.

This operation returns the coordinates of true elements in
\texttt{input}. The coordinates are returned in a 2-D tensor where the
first dimension (rows) represents the number of true elements, and the
second dimension (columns) represents the coordinates of the true
elements. Keep in mind, the shape of the output tensor can vary
depending on how many true values there are in \texttt{input}. Indices
are output in row-major order.

For example:

\begin{verbatim}
# 'input' tensor is [[True, False]
#                    [True, False]]
# 'input' has two true values, so output has two coordinates.
# 'input' has rank of 2, so coordinates have two indices.
where(input) ==> [[0, 0],
                  [1, 0]]

# `input` tensor is [[[True, False]
#                     [True, False]]
#                    [[False, True]
#                     [False, True]]
#                    [[False, False]
#                     [False, True]]]
# 'input' has 5 true values, so output has 5 coordinates.
# 'input' has rank of 3, so coordinates have three indices.
where(input) ==> [[0, 0, 0],
                  [0, 1, 0],
                  [1, 0, 1],
                  [1, 1, 1],
                  [2, 1, 1]]
\end{verbatim}

\subparagraph{Args: }\label{args-57}

\begin{itemize}
\tightlist
\item
  \texttt{input}: A \texttt{Tensor} of type \texttt{bool}.
\item
  \texttt{name}: A name for the operation (optional).
\end{itemize}

\subparagraph{Returns: }\label{returns-57}

A \texttt{Tensor} of type \texttt{int64}.

\begin{center}\rule{0.5\linewidth}{\linethickness}\end{center}

\subsubsection{\texorpdfstring{\texttt{tf.unique(x,\ name=None)}
}{tf.unique(x, name=None) }}\label{tf.uniquex-namenone}

Finds unique elements in a 1-D tensor.

This operation returns a tensor \texttt{y} containing all of the unique
elements of \texttt{x} sorted in the same order that they occur in
\texttt{x}. This operation also returns a tensor \texttt{idx} the same
size as \texttt{x} that contains the index of each value of \texttt{x}
in the unique output \texttt{y}. In other words:

\texttt{y{[}idx{[}i{]}{]}\ =\ x{[}i{]}\ for\ i\ in\ {[}0,\ 1,...,rank(x)\ -\ 1{]}}

For example:

\begin{verbatim}
# tensor 'x' is [1, 1, 2, 4, 4, 4, 7, 8, 8]
y, idx = unique(x)
y ==> [1, 2, 4, 7, 8]
idx ==> [0, 0, 1, 2, 2, 2, 3, 4, 4]
\end{verbatim}

\subparagraph{Args: }\label{args-58}

\begin{itemize}
\tightlist
\item
  \texttt{x}: A \texttt{Tensor}. 1-D.
\item
  \texttt{name}: A name for the operation (optional).
\end{itemize}

\subparagraph{Returns: }\label{returns-58}

A tuple of \texttt{Tensor} objects (y, idx).

\begin{itemize}
\tightlist
\item
  \texttt{y}: A \texttt{Tensor}. Has the same type as \texttt{x}. 1-D.
\item
  \texttt{idx}: A \texttt{Tensor} of type \texttt{int32}. 1-D.
\end{itemize}

\begin{center}\rule{0.5\linewidth}{\linethickness}\end{center}

\subsubsection{\texorpdfstring{\texttt{tf.edit\_distance(hypothesis,\ truth,\ normalize=True,\ name=\textquotesingle{}edit\_distance\textquotesingle{})}
}{tf.edit\_distance(hypothesis, truth, normalize=True, name='edit\_distance') }}\label{tf.editux5fdistancehypothesis-truth-normalizetrue-nameeditux5fdistance}

Computes the Levenshtein distance between sequences.

This operation takes variable-length sequences (\texttt{hypothesis} and
\texttt{truth}), each provided as a \texttt{SparseTensor}, and computes
the Levenshtein distance. You can normalize the edit distance by length
of \texttt{truth} by setting \texttt{normalize} to true.

For example, given the following input:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# 'hypothesis' is a tensor of shape `[2, 1]` with variable-length values:}
\CommentTok{#   (0,0) = ["a"]}
\CommentTok{#   (1,0) = ["b"]}
\NormalTok{hypothesis }\OperatorTok{=} \NormalTok{tf.SparseTensor(}
    \NormalTok{[[}\DecValTok{0}\NormalTok{, }\DecValTok{0}\NormalTok{, }\DecValTok{0}\NormalTok{],}
     \NormalTok{[}\DecValTok{1}\NormalTok{, }\DecValTok{0}\NormalTok{, }\DecValTok{0}\NormalTok{]],}
    \NormalTok{[}\StringTok{"a"}\NormalTok{, }\StringTok{"b"}\NormalTok{]}
    \NormalTok{(}\DecValTok{2}\NormalTok{, }\DecValTok{1}\NormalTok{, }\DecValTok{1}\NormalTok{))}

\CommentTok{# 'truth' is a tensor of shape `[2, 2]` with variable-length values:}
\CommentTok{#   (0,0) = []}
\CommentTok{#   (0,1) = ["a"]}
\CommentTok{#   (1,0) = ["b", "c"]}
\CommentTok{#   (1,1) = ["a"]}
\NormalTok{truth }\OperatorTok{=} \NormalTok{tf.SparseTensor(}
    \NormalTok{[[}\DecValTok{0}\NormalTok{, }\DecValTok{1}\NormalTok{, }\DecValTok{0}\NormalTok{],}
     \NormalTok{[}\DecValTok{1}\NormalTok{, }\DecValTok{0}\NormalTok{, }\DecValTok{0}\NormalTok{],}
     \NormalTok{[}\DecValTok{1}\NormalTok{, }\DecValTok{0}\NormalTok{, }\DecValTok{1}\NormalTok{],}
     \NormalTok{[}\DecValTok{1}\NormalTok{, }\DecValTok{1}\NormalTok{, }\DecValTok{0}\NormalTok{]]}
    \NormalTok{[}\StringTok{"a"}\NormalTok{, }\StringTok{"b"}\NormalTok{, }\StringTok{"c"}\NormalTok{, }\StringTok{"a"}\NormalTok{],}
    \NormalTok{(}\DecValTok{2}\NormalTok{, }\DecValTok{2}\NormalTok{, }\DecValTok{2}\NormalTok{))}

\NormalTok{normalize }\OperatorTok{=} \VariableTok{True}
\end{Highlighting}
\end{Shaded}

This operation would return the following:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# 'output' is a tensor of shape `[2, 2]` with edit distances normalized}
\CommentTok{# by 'truth' lengths.}
\NormalTok{output }\OperatorTok{==>} \NormalTok{[[inf, }\FloatTok{1.0}\NormalTok{],  }\CommentTok{# (0,0): no truth, (0,1): no hypothesis}
           \NormalTok{[}\FloatTok{0.5}\NormalTok{, }\FloatTok{1.0}\NormalTok{]]  }\CommentTok{# (1,0): addition, (1,1): no hypothesis}
\end{Highlighting}
\end{Shaded}

\subparagraph{Args: }\label{args-59}

\begin{itemize}
\tightlist
\item
  \texttt{hypothesis}: A \texttt{SparseTensor} containing hypothesis
  sequences.
\item
  \texttt{truth}: A \texttt{SparseTensor} containing truth sequences.
\item
  \texttt{normalize}: A \texttt{bool}. If \texttt{True}, normalizes the
  Levenshtein distance by length of \texttt{truth.}
\item
  \texttt{name}: A name for the operation (optional).
\end{itemize}

\subparagraph{Returns: }\label{returns-59}

A dense \texttt{Tensor} with rank \texttt{R\ -\ 1}, where R is the rank
of the \texttt{SparseTensor} inputs \texttt{hypothesis} and
\texttt{truth}.

\subparagraph{Raises: }\label{raises-1}

\begin{itemize}
\tightlist
\item
  \texttt{TypeError}: If either \texttt{hypothesis} or \texttt{truth}
  are not a \texttt{SparseTensor}.
\end{itemize}

\begin{center}\rule{0.5\linewidth}{\linethickness}\end{center}

\subsubsection{\texorpdfstring{\texttt{tf.invert\_permutation(x,\ name=None)}
}{tf.invert\_permutation(x, name=None) }}\label{tf.invertux5fpermutationx-namenone}

Computes the inverse permutation of a tensor.

This operation computes the inverse of an index permutation. It takes a
1-D integer tensor \texttt{x}, which represents the indices of a
zero-based array, and swaps each value with its index position. In other
words, for an ouput tensor \texttt{y} and an input tensor \texttt{x},
this operation computes the following:

\texttt{y{[}x{[}i{]}{]}\ =\ i\ for\ i\ in\ {[}0,\ 1,\ ...,\ len(x)\ -\ 1{]}}

The values must include 0. There can be no duplicate values or negative
values.

For example:

\begin{verbatim}
# tensor `x` is [3, 4, 0, 2, 1]
invert_permutation(x) ==> [2, 4, 3, 0, 1]
\end{verbatim}

\subparagraph{Args: }\label{args-60}

\begin{itemize}
\tightlist
\item
  \texttt{x}: A \texttt{Tensor} of type \texttt{int32}. 1-D.
\item
  \texttt{name}: A name for the operation (optional).
\end{itemize}

\subparagraph{Returns: }\label{returns-60}

A \texttt{Tensor} of type \texttt{int32}. 1-D.

